{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "V28",
      "authorship_tag": "ABX9TyMc7iLPRoOlECLfuUTdqsYy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TheCaveOfAdullam/study3/blob/main/1005Test7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "rybmB4hFozdE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2fe08c5a-ae26-4f41-c15e-3a650eb86fc4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from sklearn.preprocessing import LabelEncoder"
      ],
      "metadata": {
        "id": "V24Sjo9oo5Ps"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 기본 경로 설정\n",
        "base_dir = '/content/drive/MyDrive/ship_motor10'\n",
        "categories = ['normal', 'fault_BB', 'fault_RI', 'fault_SM']\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# 데이터 로드 및 전처리 함수 정의\n",
        "class VibrationDataset(Dataset):\n",
        "    def __init__(self, base_dir, split, categories, transform=None):\n",
        "        self.X = []\n",
        "        self.y = []\n",
        "        self.transform = transform\n",
        "        split_dir = os.path.join(base_dir, split)\n",
        "        for category in categories:\n",
        "            category_dir = os.path.join(split_dir, category)\n",
        "            files = os.listdir(category_dir)\n",
        "            for file in files:\n",
        "                file_path = os.path.join(category_dir, file)\n",
        "                data = pd.read_csv(file_path, header=None).values\n",
        "                data = pd.to_numeric(data.flatten(), errors='coerce').reshape(-1, data.shape[1])\n",
        "                data = np.nan_to_num(data).astype('float32')  # NaN 값을 0으로 대체하고, float32로 변환\n",
        "                self.X.append(data)\n",
        "                self.y.append(category)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        X = self.X[idx]\n",
        "        y = self.y[idx]\n",
        "        X = X.reshape(-1)  # 마지막 차원을 시퀀스에 병합하여 [sequence_length]로 변환\n",
        "        return torch.tensor(X, dtype=torch.float32), y\n",
        "\n",
        "# 레이블 인코딩\n",
        "label_encoder = LabelEncoder()\n",
        "\n",
        "# 데이터셋 준비\n",
        "train_dataset = VibrationDataset(base_dir, 'train', categories)\n",
        "val_dataset = VibrationDataset(base_dir, 'validation', categories)\n",
        "test_dataset = VibrationDataset(base_dir, 'test', categories)\n",
        "\n",
        "# 레이블 인코딩 및 원-핫 인코딩\n",
        "y_train_encoded = label_encoder.fit_transform([y for _, y in train_dataset])\n",
        "y_val_encoded = label_encoder.transform([y for _, y in val_dataset])\n",
        "y_test_encoded = label_encoder.transform([y for _, y in test_dataset])\n",
        "\n",
        "# 데이터셋에 레이블 추가\n",
        "train_dataset.y = y_train_encoded\n",
        "val_dataset.y = y_val_encoded\n",
        "test_dataset.y = y_test_encoded\n",
        "\n",
        "# 데이터 로더\n",
        "batch_size = 32\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
      ],
      "metadata": {
        "id": "Xuyih35Wo5Se"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CNNModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNNModel, self).__init__()\n",
        "        self.conv1 = nn.Conv1d(in_channels=1, out_channels=64, kernel_size=16, stride=16)\n",
        "        self.pool1 = nn.MaxPool1d(kernel_size=2, stride=2)\n",
        "        self.conv2 = nn.Conv1d(in_channels=64, out_channels=32, kernel_size=3, stride=1)\n",
        "        self.conv3 = nn.Conv1d(in_channels=32, out_channels=64, kernel_size=5, stride=1)\n",
        "        self.conv4 = nn.Conv1d(in_channels=64, out_channels=128, kernel_size=5, stride=1)\n",
        "        self.pool2 = nn.MaxPool1d(kernel_size=2, stride=2)\n",
        "\n",
        "        conv1_output_size = (24002 - 16) // 16 + 1\n",
        "        pool1_output_size = conv1_output_size // 2\n",
        "        conv2_output_size = (pool1_output_size - 3) // 1 + 1\n",
        "        conv3_output_size = (conv2_output_size - 5) // 1 + 1\n",
        "        conv4_output_size = (conv3_output_size - 5) // 1 + 1\n",
        "        pool2_output_size = conv4_output_size // 2\n",
        "\n",
        "        self.fc1 = nn.Linear(128 * pool2_output_size, 5000)\n",
        "        self.fc2 = nn.Linear(5000, 1000)\n",
        "        self.fc3 = nn.Linear(1000, len(categories))\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = torch.relu(x)\n",
        "        x = self.pool1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = torch.relu(x)\n",
        "        x = self.conv3(x)\n",
        "        x = torch.relu(x)\n",
        "        x = self.conv4(x)\n",
        "        x = torch.relu(x)\n",
        "\n",
        "        # 1x1 컨볼루션 적용해서 차원 맞추기\n",
        "        if hasattr(self, 'adjust_conv4'):\n",
        "            x = self.adjust_conv4(x)\n",
        "\n",
        "        x = self.pool2(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = torch.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "# 모델 초기화\n",
        "model = CNNModel().to(device)"
      ],
      "metadata": {
        "id": "NCohCBUqo5VI"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 손실 함수 및 옵티마이저\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.0001)"
      ],
      "metadata": {
        "id": "cpLatttfo5X2"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 훈련 함수\n",
        "def train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=10):\n",
        "    model.train()\n",
        "    for epoch in range(num_epochs):\n",
        "        running_loss = 0.0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        for inputs, labels in train_loader:\n",
        "            inputs, labels = inputs.unsqueeze(1).to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "        val_loss, val_accuracy = evaluate_model(model, val_loader, criterion)\n",
        "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/total:.4f}, Accuracy: {100 * correct/total:.2f}%, Val Loss: {val_loss:.4f}, Val Accuracy: {val_accuracy:.2f}%')"
      ],
      "metadata": {
        "id": "aMiw6L9so5ay"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 평가\n",
        "def evaluate_model(model, loader, criterion):\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in loader:\n",
        "            inputs, labels = inputs.unsqueeze(1).to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            val_loss += loss.item()\n",
        "\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    return val_loss / total, 100 * correct / total"
      ],
      "metadata": {
        "id": "ek_I7T0Ko5de"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 매그니튜드 기반 프루닝 함수\n",
        "def prune_by_magnitude(model, threshold):\n",
        "    for name, module in model.named_modules():\n",
        "        if isinstance(module, nn.Conv1d) or isinstance(module, nn.Linear):\n",
        "            weight_abs = torch.abs(module.weight.data)\n",
        "            mask = weight_abs > threshold\n",
        "            module.weight.data[~mask] = 0\n",
        "    print(f'Magnitude-based pruning with threshold: {threshold} applied.')\n",
        "\n",
        "# 1차 테일러 전개 기반 프루닝 함수\n",
        "def prune_by_taylor(model, threshold):\n",
        "    for name, module in model.named_modules():\n",
        "        if isinstance(module, nn.Conv1d) or isinstance(module, nn.Linear):\n",
        "            importance = torch.abs(module.weight * module.weight.grad)\n",
        "            mask = importance > threshold\n",
        "            with torch.no_grad():\n",
        "                module.weight[~mask] = 0\n",
        "    print(f'Taylor expansion-based pruning with threshold: {threshold} applied.')"
      ],
      "metadata": {
        "id": "DnDizFgQo54F"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prune_filters_with_zero_weight_ratio(model, threshold=0.9):\n",
        "    \"\"\"필터의 가중치가 90% 이상 0일 경우 필터를 제거하고, 다음 레이어의 입력 채널을 맞춤.\"\"\"\n",
        "\n",
        "    layers_to_prune = []  # 나중에 교체할 레이어를 기록해두기 위한 리스트\n",
        "    prev_out_channels = None  # 이전 레이어의 출력 채널 수를 저장할 변수\n",
        "\n",
        "    for name, module in list(model.named_modules()):\n",
        "        if isinstance(module, nn.Conv1d):\n",
        "            weight = module.weight.detach().cpu().numpy()\n",
        "            zero_ratio_per_filter = np.mean(weight == 0, axis=(1, 2))  # 필터별로 0의 비율 계산\n",
        "\n",
        "            # 0의 비율이 threshold 이상인 필터의 인덱스를 추출\n",
        "            prune_indices = [i for i, ratio in enumerate(zero_ratio_per_filter) if ratio >= threshold]\n",
        "\n",
        "            if prune_indices:\n",
        "                # 필터 제거 후 새로운 가중치 텐서 생성\n",
        "                new_weight = torch.cat([w.unsqueeze(0) for i, w in enumerate(module.weight) if i not in prune_indices], dim=0)\n",
        "                new_bias = torch.cat([b.unsqueeze(0) for i, b in enumerate(module.bias) if i not in prune_indices], dim=0)\n",
        "\n",
        "                # 새로운 레이어 정의\n",
        "                new_layer = nn.Conv1d(\n",
        "                    in_channels=module.in_channels,\n",
        "                    out_channels=new_weight.size(0),  # 남은 필터 수\n",
        "                    kernel_size=module.kernel_size,\n",
        "                    stride=module.stride,\n",
        "                    padding=module.padding\n",
        "                )\n",
        "                new_layer.weight = nn.Parameter(new_weight)\n",
        "                new_layer.bias = nn.Parameter(new_bias)\n",
        "\n",
        "                # 프루닝 후 레이어 출력 채널 수를 저장\n",
        "                prev_out_channels = new_weight.size(0)\n",
        "\n",
        "                # 레이어 교체를 기록\n",
        "                layers_to_prune.append((name, new_layer))\n",
        "\n",
        "        # 다음 레이어가 Conv1d일 경우, 입력 채널을 프루닝된 출력 채널로 수정\n",
        "        if prev_out_channels and isinstance(module, nn.Conv1d) and module.in_channels != prev_out_channels:\n",
        "            new_layer = nn.Conv1d(\n",
        "                in_channels=prev_out_channels,  # 프루닝된 레이어의 출력 채널을 입력 채널로 설정\n",
        "                out_channels=module.out_channels,\n",
        "                kernel_size=module.kernel_size,\n",
        "                stride=module.stride,\n",
        "                padding=module.padding\n",
        "            )\n",
        "            new_layer.weight = module.weight\n",
        "            new_layer.bias = module.bias\n",
        "\n",
        "            # 레이어 교체를 기록\n",
        "            layers_to_prune.append((name, new_layer))\n",
        "\n",
        "    # 레이어 교체 (모델을 순회한 후에 교체해야 함)\n",
        "    for name, new_layer in layers_to_prune:\n",
        "        parent_module, layer_name = find_parent_module(model, name)\n",
        "        setattr(parent_module, layer_name, new_layer)\n",
        "\n",
        "    print(f'Filters pruned based on zero weight ratio (threshold={threshold}).')\n",
        "    return model\n",
        "\n",
        "\n",
        "def find_parent_module(model, layer_name):\n",
        "    \"\"\"모델에서 주어진 레이어 이름을 가진 모듈의 부모 모듈과 해당 모듈의 이름을 찾는 함수.\"\"\"\n",
        "    parts = layer_name.split(\".\")\n",
        "    current_module = model\n",
        "    for part in parts[:-1]:\n",
        "        current_module = getattr(current_module, part)\n",
        "    return current_module, parts[-1]"
      ],
      "metadata": {
        "id": "VR_TDwFGqG7c"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. 초기 7 에폭 훈련\n",
        "train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=3)"
      ],
      "metadata": {
        "id": "H78_6HUPqG-N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f36b5bb9-43db-446a-b67c-32d7c7cd01a5"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/3], Loss: 0.0391, Accuracy: 50.00%, Val Loss: 0.0393, Val Accuracy: 50.00%\n",
            "Epoch [2/3], Loss: 0.0390, Accuracy: 50.00%, Val Loss: 0.0392, Val Accuracy: 50.00%\n",
            "Epoch [3/3], Loss: 0.0313, Accuracy: 60.17%, Val Loss: 0.0055, Val Accuracy: 99.22%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. 매그니튜드 기반 프루닝 적용\n",
        "magnitude_threshold = 0.1\n",
        "prune_by_magnitude(model, magnitude_threshold)"
      ],
      "metadata": {
        "id": "-C7_QAq0qHAn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8bae981a-5069-412e-ba20-08cd9ee2dc49"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Magnitude-based pruning with threshold: 0.1 applied.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. 매그니튜드 기반 프루닝 후 파인튜닝\n",
        "train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=1)"
      ],
      "metadata": {
        "id": "FcWiGrZcqHC9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5a410b6d-3a26-4952-a359-2220ef705c93"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/1], Loss: 0.0392, Accuracy: 50.00%, Val Loss: 0.0398, Val Accuracy: 50.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. 1차 테일러 전개 기반 프루닝 적용\n",
        "taylor_threshold = 0.001\n",
        "prune_by_taylor(model, taylor_threshold)"
      ],
      "metadata": {
        "id": "lgFmCpOHqHFe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "04a30073-89aa-4538-aa1e-4b1a253d9b24"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Taylor expansion-based pruning with threshold: 0.001 applied.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. 테일러 전개 기반 프루닝 후 파인튜닝\n",
        "train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=3)"
      ],
      "metadata": {
        "id": "grED_P4SqHHp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e5f6f60b-bb3e-4b8d-beac-99a739aeb456"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/3], Loss: 0.0392, Accuracy: 50.00%, Val Loss: 0.0393, Val Accuracy: 50.00%\n",
            "Epoch [2/3], Loss: 0.0389, Accuracy: 50.00%, Val Loss: 0.0393, Val Accuracy: 50.00%\n",
            "Epoch [3/3], Loss: 0.0389, Accuracy: 50.00%, Val Loss: 0.0393, Val Accuracy: 50.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 6. 구조적 프루닝 (90% 이상의 필터 제거)\n",
        "model = prune_filters_with_zero_weight_ratio(model, threshold=0.7)"
      ],
      "metadata": {
        "id": "_ugqfGtCqHKO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "41549a6b-303c-4f22-d8d8-b7f4c0169a36"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Filters pruned based on zero weight ratio (threshold=0.7).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 7. 구조적 프루닝 후 파인튜닝\n",
        "train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=3)"
      ],
      "metadata": {
        "id": "N8ISlajPo56x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "45a59481-f5c6-41b4-c856-c56220280d02"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/3], Loss: 0.0389, Accuracy: 50.00%, Val Loss: 0.0393, Val Accuracy: 50.00%\n",
            "Epoch [2/3], Loss: 0.0389, Accuracy: 50.00%, Val Loss: 0.0393, Val Accuracy: 50.00%\n",
            "Epoch [3/3], Loss: 0.0389, Accuracy: 50.00%, Val Loss: 0.0393, Val Accuracy: 50.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 테스트 성능 확인\n",
        "test_loss, test_accuracy = evaluate_model(model, test_loader, criterion)\n",
        "print(f'Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.2f}%')"
      ],
      "metadata": {
        "id": "5KKzixaOo59X",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "57ae70b6-4a7e-457f-e0ca-715c331a8534"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 0.0393, Test Accuracy: 50.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 저장\n",
        "torch.save(model.state_dict(), 'model.pth')"
      ],
      "metadata": {
        "id": "NMi-0Dx2qW5Y"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 사이즈 확인\n",
        "model_size = os.path.getsize('model.pth') / (1024 * 1024)\n",
        "print(f\"Model Size: {model_size:.2f} MB\")"
      ],
      "metadata": {
        "id": "ouU9VMmwqW78",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8de0c4d4-0fd6-4d85-9790-eba8122932e2"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Size: 922.66 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 파라미터 수 확인\n",
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "total_params = count_parameters(model)\n",
        "print(f\"Total number of trainable parameters: {total_params}\")"
      ],
      "metadata": {
        "id": "rn1n-6OBqW-X",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c0833dd-85cb-49dd-a061-110d17af5b80"
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of trainable parameters: 241868660\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def check_zero_ratio(model):\n",
        "    for name, module in model.named_modules():\n",
        "        if isinstance(module, nn.Conv1d):\n",
        "            weight = module.weight.detach().cpu().numpy()\n",
        "            zero_ratio_per_filter = np.mean(weight == 0, axis=(1, 2))\n",
        "            print(f\"Layer: {name}, Zero ratio per filter: {zero_ratio_per_filter}\")\n",
        "\n",
        "# 프루닝 후 0 가중치 비율 확인\n",
        "check_zero_ratio(model)"
      ],
      "metadata": {
        "id": "0fUqJlV-qXAs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "62db0821-c048-4976-b990-0117219c4e48"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layer: conv1, Zero ratio per filter: [0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 1. 0. 1. 1. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0.\n",
            " 0. 0. 1. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "Layer: conv2, Zero ratio per filter: [1.         0.51041667 0.234375   0.234375   0.23958333 0.328125\n",
            " 0.234375   0.28125    0.234375   1.         0.41666667 0.28125\n",
            " 0.28125    0.3125     1.         0.25520833 0.23958333 0.234375\n",
            " 0.27083333 0.296875   0.234375   0.234375   0.28125    0.234375\n",
            " 0.234375   0.234375   0.23958333 0.328125   0.28125    0.234375\n",
            " 0.48958333 0.234375  ]\n",
            "Layer: conv3, Zero ratio per filter: [0.23125 1.      0.38125 0.10625 0.10625 0.15    1.      0.1125  1.\n",
            " 0.10625 1.      0.1375  0.125   1.      0.5     0.14375 0.10625 0.425\n",
            " 1.      0.10625 0.23125 0.1375  0.15625 0.15625 0.21875 0.59375 1.\n",
            " 0.10625 1.      0.1375  1.      0.23125 0.10625 1.      0.1375  0.125\n",
            " 0.10625 0.10625 0.15625 0.10625 0.10625 0.1875  0.10625 0.375   0.36875\n",
            " 0.10625 0.15625 0.3375  0.125   0.375   0.10625 1.      1.      0.10625\n",
            " 1.      0.34375 0.16875 0.10625 0.28125 1.      0.10625 0.11875 0.2625\n",
            " 0.15625]\n",
            "Layer: conv4, Zero ratio per filter: [0.21875  0.234375 0.25     0.28125  0.234375 1.       0.515625 0.21875\n",
            " 0.34375  0.21875  1.       0.421875 0.415625 0.328125 0.25     0.225\n",
            " 0.228125 0.21875  1.       0.55625  0.35     1.       0.25     0.359375\n",
            " 0.5125   0.390625 0.325    0.296875 0.234375 0.21875  0.26875  0.25\n",
            " 1.       0.490625 1.       0.21875  1.       1.       0.234375 0.225\n",
            " 1.       1.       1.       0.21875  0.221875 0.515625 0.253125 0.265625\n",
            " 0.271875 0.221875 0.265625 1.       1.       0.234375 0.21875  1.\n",
            " 0.421875 0.234375 0.340625 1.       0.265625 1.       1.       0.421875\n",
            " 0.221875 0.21875  0.234375 0.296875 0.34375  0.296875 0.26875  1.\n",
            " 0.28125  0.21875  0.84375  1.       1.       0.328125 0.278125 1.\n",
            " 1.       0.359375 0.221875 0.234375 0.21875  0.25     0.228125 0.234375\n",
            " 0.21875  1.       0.234375 1.       1.       0.459375 1.       0.271875\n",
            " 1.       1.       0.221875 1.       1.       0.221875 0.21875  1.\n",
            " 0.234375 1.       0.546875 0.21875  0.265625 1.       0.234375 1.\n",
            " 0.234375 0.21875  0.21875  1.       0.21875  1.       1.       0.21875\n",
            " 0.265625 0.421875 0.296875 0.234375 0.234375 0.21875  0.234375 0.421875]\n"
          ]
        }
      ]
    }
  ]
}