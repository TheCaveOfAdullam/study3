{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "V28",
      "authorship_tag": "ABX9TyNOfepEdURiYmpbIXXKVphc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TheCaveOfAdullam/study3/blob/main/1025Test8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bnF4tMl4hbGp",
        "outputId": "1d183cad-ab2c-4b12-98f6-032d6d28eca2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# 필요한 라이브러리 설치 및 Google Drive 마운트\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch_pruning"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s-OByVQmhr17",
        "outputId": "69bcf11f-a882-4eb2-f091-041362277fd0"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch_pruning\n",
            "  Downloading torch_pruning-1.4.3-py3-none-any.whl.metadata (29 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from torch_pruning) (2.5.0+cpu)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch_pruning) (1.26.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->torch_pruning) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->torch_pruning) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->torch_pruning) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->torch_pruning) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->torch_pruning) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch->torch_pruning) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch->torch_pruning) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->torch_pruning) (3.0.2)\n",
            "Downloading torch_pruning-1.4.3-py3-none-any.whl (62 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/62.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.9/62.9 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torch_pruning\n",
            "Successfully installed torch_pruning-1.4.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.utils as utils\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import torch.nn.utils.prune as prune\n",
        "import torch_pruning as tp"
      ],
      "metadata": {
        "id": "K-78an4rhr4q"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 기본 경로 설정\n",
        "base_dir = '/content/drive/MyDrive/ship_motor10'\n",
        "categories = ['normal', 'fault_BB', 'fault_RI', 'fault_SM']\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# 데이터 로드 및 전처리 함수 정의\n",
        "class VibrationDataset(Dataset):\n",
        "    def __init__(self, base_dir, split, categories, transform=None):\n",
        "        self.X = []\n",
        "        self.y = []\n",
        "        self.transform = transform\n",
        "        split_dir = os.path.join(base_dir, split)\n",
        "        for category in categories:\n",
        "            category_dir = os.path.join(split_dir, category)\n",
        "            files = os.listdir(category_dir)\n",
        "            for file in files:\n",
        "                file_path = os.path.join(category_dir, file)\n",
        "                data = pd.read_csv(file_path, header=None).values\n",
        "                data = pd.to_numeric(data.flatten(), errors='coerce').reshape(-1, data.shape[1])\n",
        "                data = np.nan_to_num(data).astype('float32')\n",
        "                self.X.append(data)\n",
        "                self.y.append(category)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        X = self.X[idx]\n",
        "        y = self.y[idx]\n",
        "        X = X.reshape(-1)\n",
        "        return torch.tensor(X, dtype=torch.float32), y\n",
        "\n",
        "# 레이블 인코딩\n",
        "label_encoder = LabelEncoder()\n",
        "\n",
        "# 데이터셋 준비\n",
        "train_dataset = VibrationDataset(base_dir, 'train', categories)\n",
        "val_dataset = VibrationDataset(base_dir, 'validation', categories)\n",
        "test_dataset = VibrationDataset(base_dir, 'test', categories)\n",
        "\n",
        "# 레이블 인코딩 및 원-핫 인코딩\n",
        "y_train_encoded = label_encoder.fit_transform([y for _, y in train_dataset])\n",
        "y_val_encoded = label_encoder.transform([y for _, y in val_dataset])\n",
        "y_test_encoded = label_encoder.transform([y for _, y in test_dataset])\n",
        "\n",
        "# 데이터셋에 레이블 추가\n",
        "train_dataset.y = y_train_encoded\n",
        "val_dataset.y = y_val_encoded\n",
        "test_dataset.y = y_test_encoded\n",
        "\n",
        "# 데이터 로더\n",
        "batch_size = 32\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
      ],
      "metadata": {
        "id": "KL55qpjRhr7S"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CNN 모델 정의\n",
        "class CNNModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNNModel, self).__init__()\n",
        "        self.conv1 = nn.Conv1d(in_channels=1, out_channels=64, kernel_size=16, stride=16)\n",
        "        self.pool1 = nn.MaxPool1d(kernel_size=2, stride=2)\n",
        "        self.conv2 = nn.Conv1d(in_channels=64, out_channels=32, kernel_size=3, stride=1)\n",
        "        self.conv3 = nn.Conv1d(in_channels=32, out_channels=64, kernel_size=5, stride=1)\n",
        "        self.conv4 = nn.Conv1d(in_channels=64, out_channels=128, kernel_size=5, stride=1)\n",
        "        self.pool2 = nn.MaxPool1d(kernel_size=2, stride=2)\n",
        "\n",
        "        conv1_output_size = (24002 - 16) // 16 + 1\n",
        "        pool1_output_size = conv1_output_size // 2\n",
        "        conv2_output_size = (pool1_output_size - 3) // 1 + 1\n",
        "        conv3_output_size = (conv2_output_size - 5) // 1 + 1\n",
        "        conv4_output_size = (conv3_output_size - 5) // 1 + 1\n",
        "        pool2_output_size = conv4_output_size // 2\n",
        "\n",
        "        self.fc1 = nn.Linear(128 * pool2_output_size, 5000)\n",
        "        self.fc2 = nn.Linear(5000, 1000)\n",
        "        self.fc3 = nn.Linear(1000, len(categories))\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = torch.relu(x)\n",
        "        x = self.pool1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = torch.relu(x)\n",
        "        x = self.conv3(x)\n",
        "        x = torch.relu(x)\n",
        "        x = self.conv4(x)\n",
        "        x = torch.relu(x)\n",
        "        x = self.pool2(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = torch.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "sns7_PR9hr9z"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1차 테일러 전개 기반 비구조적 프루닝 (마스크 적용)\n",
        "def prune_by_taylor_with_mask(model, threshold=0.01):\n",
        "    for name, module in model.named_modules():\n",
        "        if isinstance(module, nn.Conv1d) or isinstance(module, nn.Linear):\n",
        "            if module.weight.grad is None:\n",
        "                raise ValueError(f\"Gradients not found for {name}. Run backward pass before pruning.\")\n",
        "\n",
        "            importance = torch.abs(module.weight * module.weight.grad)\n",
        "            mask = importance > threshold\n",
        "            prune.custom_from_mask(module, name='weight', mask=mask)\n",
        "    print(f\"Taylor expansion-based pruning with threshold: {threshold} applied with mask.\")\n",
        "\n",
        "# 0 비율 기반 필터 감지 및 구조적 프루닝 적용 함수\n",
        "def detect_and_apply_structural_pruning_with_zero_ratio(model, prune_threshold=0.7, example_inputs=None):\n",
        "    if example_inputs is None:\n",
        "        example_inputs = torch.randn(1, 1, 24002).to(next(model.parameters()).device)\n",
        "\n",
        "    DG = tp.DependencyGraph().build_dependency(model, example_inputs=example_inputs)\n",
        "\n",
        "    total_pruned = 0\n",
        "    for name, module in model.named_modules():\n",
        "        if isinstance(module, nn.Conv1d) or isinstance(module, nn.Linear):\n",
        "            # **출력 레이어는 프루닝 대상에서 제외**\n",
        "            if name == 'fc3':\n",
        "                print(f\"Skipping pruning for {name} (output layer).\")\n",
        "                continue\n",
        "\n",
        "            weight_data = module.weight.detach().cpu().numpy()\n",
        "            # 0 비율 계산\n",
        "            if isinstance(module, nn.Conv1d):\n",
        "                filter_zero_percentage = np.mean(weight_data == 0, axis=(1, 2))\n",
        "            else:\n",
        "                filter_zero_percentage = np.mean(weight_data == 0, axis=1)\n",
        "            prune_indices = np.where(filter_zero_percentage >= prune_threshold)[0]\n",
        "\n",
        "            if len(prune_indices) > 0 and len(prune_indices) < module.weight.shape[0]:\n",
        "                pruning_group = None\n",
        "                if isinstance(module, nn.Conv1d):\n",
        "                    pruning_group = DG.get_pruning_group(module, tp.prune_conv_out_channels, idxs=prune_indices)\n",
        "                elif isinstance(module, nn.Linear):\n",
        "                    pruning_group = DG.get_pruning_group(module, tp.prune_linear_out_channels, idxs=prune_indices)\n",
        "\n",
        "                if pruning_group is not None:\n",
        "                    pruning_group.prune()\n",
        "                    total_pruned += len(prune_indices)\n",
        "                    print(f\"Pruned {len(prune_indices)} filters/neuron(s) from {name}.\")\n",
        "            else:\n",
        "                print(f\"Skipping pruning for {name} as it would remove all filters/neuron(s).\")\n",
        "\n",
        "    print(f\"Structural pruning based on zero ratio applied. {total_pruned} filters/neuron(s) pruned in total.\")\n",
        "    return model"
      ],
      "metadata": {
        "id": "NK5vPz97hsAR"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 0인 가중치에 마스크 재적용하여 업데이트 방지\n",
        "def apply_mask_to_zero_weights(model):\n",
        "    for name, module in model.named_modules():\n",
        "        if isinstance(module, nn.Conv1d) or isinstance(module, nn.Linear):\n",
        "            # 현재 가중치가 0인 위치에 대한 마스크 생성\n",
        "            weight_mask = (module.weight.data != 0).float()\n",
        "            # 마스크를 레이어에 적용\n",
        "            prune.CustomFromMask.apply(module, 'weight', mask=weight_mask)"
      ],
      "metadata": {
        "id": "oZrE5zXHdAf3"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 학습 함수\n",
        "def train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=5, max_norm=1.0):\n",
        "    model.train()\n",
        "    for epoch in range(num_epochs):\n",
        "        running_loss = 0.0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        for inputs, labels in train_loader:\n",
        "            inputs, labels = inputs.unsqueeze(1).to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "\n",
        "            # 0인 가중치의 기울기를 0으로 설정하여 업데이트 방지\n",
        "            for name, param in model.named_parameters():\n",
        "                if 'weight' in name:\n",
        "                    if param.grad is not None:\n",
        "                        param.grad.data[param.data == 0] = 0\n",
        "\n",
        "            utils.clip_grad_norm_(model.parameters(), max_norm)\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "        val_loss, val_accuracy = evaluate_model(model, val_loader, criterion)\n",
        "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/total:.4f}, Accuracy: {100 * correct/total:.2f}%, Val Loss: {val_loss:.4f}, Val Accuracy: {val_accuracy:.2f}%')\n",
        "\n",
        "    return model\n",
        "\n",
        "# 모델 평가 함수\n",
        "def evaluate_model(model, loader, criterion):\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in loader:\n",
        "            inputs, labels = inputs.unsqueeze(1).to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            val_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    return val_loss / total, 100 * correct / total"
      ],
      "metadata": {
        "id": "ujVDBm7EhsCp"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 프루닝 및 재학습 과정\n",
        "def prune_and_retrain_with_mask(model, train_loader, val_loader, test_loader, criterion, device, optimizer_params, threshold_taylor=0.01, prune_threshold=0.7):\n",
        "    optimizer = optim.Adam(model.parameters(), **optimizer_params)\n",
        "\n",
        "    print(\"Initial training before pruning\")\n",
        "    model = train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=5)\n",
        "\n",
        "    print(\"Step 1: Taylor expansion-based pruning with mask\")\n",
        "    # 프루닝을 위한 한 번의 forward 및 backward 패스 수행\n",
        "    for inputs, labels in train_loader:\n",
        "        inputs, labels = inputs.unsqueeze(1).to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        break  # 프루닝을 위해 한 배치만 필요\n",
        "\n",
        "    prune_by_taylor_with_mask(model, threshold_taylor)\n",
        "\n",
        "    # 비구조적 프루닝 후 모델 재학습\n",
        "    optimizer = optim.Adam(model.parameters(), **optimizer_params)\n",
        "    model = train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=5)\n",
        "\n",
        "    # 구조적 프루닝 전에 프루닝 마스크 제거\n",
        "    print(\"Removing pruning masks before structural pruning\")\n",
        "    for name, module in model.named_modules():\n",
        "        if isinstance(module, nn.Conv1d) or isinstance(module, nn.Linear):\n",
        "            try:\n",
        "                prune.remove(module, 'weight')\n",
        "            except ValueError:\n",
        "                pass  # 프루닝이 적용되지 않은 레이어는 건너뜁니다\n",
        "\n",
        "    print(\"Step 2: Structural pruning based on zero ratio\")\n",
        "    model = detect_and_apply_structural_pruning_with_zero_ratio(model, prune_threshold=prune_threshold)\n",
        "\n",
        "    # 0인 가중치에 마스크 재적용하여 업데이트 방지\n",
        "    print(\"Reapplying mask to zero weights to prevent them from updating\")\n",
        "    apply_mask_to_zero_weights(model)\n",
        "\n",
        "    # 구조적 프루닝 후 모델 재학습\n",
        "    optimizer = optim.Adam(model.parameters(), **optimizer_params)\n",
        "    model = train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=10)\n",
        "\n",
        "    # 재학습 후 프루닝 마스크 제거\n",
        "    print(\"Removing pruning masks after retraining\")\n",
        "    for name, module in model.named_modules():\n",
        "        if isinstance(module, nn.Conv1d) or isinstance(module, nn.Linear):\n",
        "            try:\n",
        "                prune.remove(module, 'weight')\n",
        "            except ValueError:\n",
        "                pass  # 프루닝이 적용되지 않은 레이어는 건너뜁니다\n",
        "\n",
        "    print(\"Final evaluation on the test set...\")\n",
        "    test_loss, test_accuracy = evaluate_model(model, test_loader, criterion)\n",
        "    print(f'Final Test Loss: {test_loss:.4f}, Final Test Accuracy: {test_accuracy:.2f}%')\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "93NDr3s_hsFj"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 파라미터 설정 및 프루닝 실행\n",
        "model = CNNModel().to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer_params = {'lr': 0.0001, 'weight_decay': 1e-5}"
      ],
      "metadata": {
        "id": "XCqCDSxLhsIA"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 비제로 가중치 계산 함수\n",
        "def count_nonzero_weights(model):\n",
        "    nonzero_count = 0\n",
        "    total_count = 0\n",
        "    for name, param in model.named_parameters():\n",
        "        if param.requires_grad:\n",
        "            nonzero_count += torch.sum(param != 0).item()  # 0이 아닌 가중치 수 계산\n",
        "            total_count += param.numel()  # 전체 가중치 수 계산\n",
        "    return nonzero_count, total_count\n",
        "\n",
        "# 비제로 가중치 수 계산\n",
        "nonzero_weights, total_weights = count_nonzero_weights(model)\n",
        "print(f\"Number of non-zero weights: {nonzero_weights}\")\n",
        "print(f\"Total number of weights: {total_weights}\")\n",
        "print(f\"Percentage of non-zero weights: {100 * nonzero_weights / total_weights:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uvcOHbCmiLkx",
        "outputId": "e79b7495-08de-4c4b-dcfe-98a3ef4050c8"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of non-zero weights: 241868647\n",
            "Total number of weights: 241868660\n",
            "Percentage of non-zero weights: 100.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = prune_and_retrain_with_mask(model, train_loader, val_loader, test_loader, criterion, device, optimizer_params, threshold_taylor=0.00001, prune_threshold=0.9)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aVMTPXLUhsKA",
        "outputId": "4187f335-dcb4-4006-f30e-675d25dee3cd"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial training before pruning\n",
            "Epoch [1/5], Loss: 0.0391, Accuracy: 49.94%, Val Loss: 0.0393, Val Accuracy: 50.00%\n",
            "Epoch [2/5], Loss: 0.0390, Accuracy: 50.00%, Val Loss: 0.0392, Val Accuracy: 50.00%\n",
            "Epoch [3/5], Loss: 0.0353, Accuracy: 52.95%, Val Loss: 0.0185, Val Accuracy: 66.67%\n",
            "Epoch [4/5], Loss: 0.0184, Accuracy: 72.16%, Val Loss: 0.0143, Val Accuracy: 98.59%\n",
            "Epoch [5/5], Loss: 0.0117, Accuracy: 87.29%, Val Loss: 0.0102, Val Accuracy: 98.89%\n",
            "Step 1: Taylor expansion-based pruning with mask\n",
            "Taylor expansion-based pruning with threshold: 1e-05 applied with mask.\n",
            "Epoch [1/5], Loss: 0.0483, Accuracy: 49.95%, Val Loss: 0.0299, Val Accuracy: 66.67%\n",
            "Epoch [2/5], Loss: 0.0262, Accuracy: 67.64%, Val Loss: 0.0210, Val Accuracy: 66.78%\n",
            "Epoch [3/5], Loss: 0.0183, Accuracy: 78.47%, Val Loss: 0.0144, Val Accuracy: 83.33%\n",
            "Epoch [4/5], Loss: 0.0140, Accuracy: 82.07%, Val Loss: 0.0093, Val Accuracy: 86.52%\n",
            "Epoch [5/5], Loss: 0.0105, Accuracy: 88.44%, Val Loss: 0.0286, Val Accuracy: 62.11%\n",
            "Removing pruning masks before structural pruning\n",
            "Step 2: Structural pruning based on zero ratio\n",
            "Pruned 21 filters/neuron(s) from conv1.\n",
            "Pruned 13 filters/neuron(s) from conv2.\n",
            "Pruned 25 filters/neuron(s) from conv3.\n",
            "Pruned 63 filters/neuron(s) from conv4.\n",
            "Pruned 4987 filters/neuron(s) from fc1.\n",
            "Pruned 558 filters/neuron(s) from fc2.\n",
            "Skipping pruning for fc3 (output layer).\n",
            "Structural pruning based on zero ratio applied. 5667 filters/neuron(s) pruned in total.\n",
            "Reapplying mask to zero weights to prevent them from updating\n",
            "Epoch [1/10], Loss: 0.0154, Accuracy: 81.04%, Val Loss: 0.0131, Val Accuracy: 93.81%\n",
            "Epoch [2/10], Loss: 0.0098, Accuracy: 87.83%, Val Loss: 0.0047, Val Accuracy: 96.44%\n",
            "Epoch [3/10], Loss: 0.0161, Accuracy: 82.36%, Val Loss: 0.0054, Val Accuracy: 95.63%\n",
            "Epoch [4/10], Loss: 0.0022, Accuracy: 97.48%, Val Loss: 0.0005, Val Accuracy: 99.96%\n",
            "Epoch [5/10], Loss: 0.0046, Accuracy: 94.22%, Val Loss: 0.0012, Val Accuracy: 99.15%\n",
            "Epoch [6/10], Loss: 0.0017, Accuracy: 97.62%, Val Loss: 0.0001, Val Accuracy: 100.00%\n",
            "Epoch [7/10], Loss: 0.0027, Accuracy: 96.70%, Val Loss: 0.0004, Val Accuracy: 99.70%\n",
            "Epoch [8/10], Loss: 0.0070, Accuracy: 93.35%, Val Loss: 0.0003, Val Accuracy: 99.63%\n",
            "Epoch [9/10], Loss: 0.0037, Accuracy: 96.21%, Val Loss: 0.0001, Val Accuracy: 99.93%\n",
            "Epoch [10/10], Loss: 0.0001, Accuracy: 99.98%, Val Loss: 0.0000, Val Accuracy: 100.00%\n",
            "Removing pruning masks after retraining\n",
            "Final evaluation on the test set...\n",
            "Final Test Loss: 0.0002, Final Test Accuracy: 99.74%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 최종 테스트 평가\n",
        "print(\"Final evaluation on the test set...\")\n",
        "test_loss, test_accuracy = evaluate_model(model, test_loader, criterion)\n",
        "print(f'Final Test Loss: {test_loss:.4f}, Final Test Accuracy: {test_accuracy:.2f}%')"
      ],
      "metadata": {
        "id": "GuimCrYnhsMw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "06a95f3e-8a9a-48d7-d7bc-c6797fe3a5c8"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final evaluation on the test set...\n",
            "Final Test Loss: 0.0002, Final Test Accuracy: 99.74%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 비제로 가중치 계산 함수\n",
        "def count_nonzero_weights(model):\n",
        "    nonzero_count = 0\n",
        "    total_count = 0\n",
        "    for name, param in model.named_parameters():\n",
        "        if param.requires_grad:\n",
        "            nonzero_count += torch.sum(param != 0).item()  # 0이 아닌 가중치 수 계산\n",
        "            total_count += param.numel()  # 전체 가중치 수 계산\n",
        "    return nonzero_count, total_count\n",
        "\n",
        "# 비제로 가중치 수 계산\n",
        "nonzero_weights, total_weights = count_nonzero_weights(model)\n",
        "print(f\"Number of non-zero weights: {nonzero_weights}\")\n",
        "print(f\"Total number of weights: {total_weights}\")\n",
        "print(f\"Percentage of non-zero weights: {100 * nonzero_weights / total_weights:.2f}%\")"
      ],
      "metadata": {
        "id": "gzvudeAKhsPX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e95b9e2-e3f8-4628-c30f-485910c13549"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of non-zero weights: 82522\n",
            "Total number of weights: 340308\n",
            "Percentage of non-zero weights: 24.25%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xFTyiFbwhsR8"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yXnMy4v9hsUo"
      },
      "execution_count": 14,
      "outputs": []
    }
  ]
}