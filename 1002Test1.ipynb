{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TheCaveOfAdullam/study3/blob/main/1002Test1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sZAWQMtD12DW",
        "outputId": "1383a939-2c76-4e83-f84a-d0cd0c52ee4e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "Dio5mJ4217DW"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import torch.nn.utils.prune as prune"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "7XXe1awD17F5"
      },
      "outputs": [],
      "source": [
        "# 기본 경로 설정\n",
        "base_dir = '/content/drive/MyDrive/ship_motor10'\n",
        "categories = ['normal', 'fault_BB', 'fault_RI', 'fault_SM']\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# 데이터 로드 및 전처리 함수 정의\n",
        "class VibrationDataset(Dataset):\n",
        "    def __init__(self, base_dir, split, categories, transform=None):\n",
        "        self.X = []\n",
        "        self.y = []\n",
        "        self.transform = transform\n",
        "        split_dir = os.path.join(base_dir, split)\n",
        "        for category in categories:\n",
        "            category_dir = os.path.join(split_dir, category)\n",
        "            files = os.listdir(category_dir)\n",
        "            for file in files:\n",
        "                file_path = os.path.join(category_dir, file)\n",
        "                data = pd.read_csv(file_path, header=None).values\n",
        "                data = pd.to_numeric(data.flatten(), errors='coerce').reshape(-1, data.shape[1])\n",
        "                data = np.nan_to_num(data).astype('float32')  # NaN 값을 0으로 대체하고, float32로 변환\n",
        "                self.X.append(data)\n",
        "                self.y.append(category)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        X = self.X[idx]\n",
        "        y = self.y[idx]\n",
        "        X = X.reshape(-1)  # 마지막 차원을 시퀀스에 병합하여 [sequence_length]로 변환\n",
        "        return torch.tensor(X, dtype=torch.float32), y\n",
        "\n",
        "# 레이블 인코딩\n",
        "label_encoder = LabelEncoder()\n",
        "\n",
        "# 데이터셋 준비\n",
        "train_dataset = VibrationDataset(base_dir, 'train', categories)\n",
        "val_dataset = VibrationDataset(base_dir, 'validation', categories)\n",
        "test_dataset = VibrationDataset(base_dir, 'test', categories)\n",
        "\n",
        "# 레이블 인코딩 및 원-핫 인코딩\n",
        "y_train_encoded = label_encoder.fit_transform([y for _, y in train_dataset])\n",
        "y_val_encoded = label_encoder.transform([y for _, y in val_dataset])\n",
        "y_test_encoded = label_encoder.transform([y for _, y in test_dataset])\n",
        "\n",
        "# 데이터셋에 레이블 추가\n",
        "train_dataset.y = y_train_encoded\n",
        "val_dataset.y = y_val_encoded\n",
        "test_dataset.y = y_test_encoded\n",
        "\n",
        "# 데이터 로더\n",
        "batch_size = 32\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "JTQ5QdkH17Ie"
      },
      "outputs": [],
      "source": [
        "class CNNModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNNModel, self).__init__()\n",
        "        self.conv1 = nn.Conv1d(in_channels=1, out_channels=64, kernel_size=16, stride=16)\n",
        "        self.pool1 = nn.MaxPool1d(kernel_size=2, stride=2)\n",
        "        self.conv2 = nn.Conv1d(in_channels=64, out_channels=32, kernel_size=3, stride=1)\n",
        "        self.conv3 = nn.Conv1d(in_channels=32, out_channels=64, kernel_size=5, stride=1)\n",
        "        self.conv4 = nn.Conv1d(in_channels=64, out_channels=128, kernel_size=5, stride=1)\n",
        "        self.pool2 = nn.MaxPool1d(kernel_size=2, stride=2)\n",
        "\n",
        "        # 계산된 출력 크기\n",
        "        conv1_output_size = (24002 - 16) // 16 + 1\n",
        "        pool1_output_size = conv1_output_size // 2\n",
        "        conv2_output_size = (pool1_output_size - 3) // 1 + 1\n",
        "        conv3_output_size = (conv2_output_size - 5) // 1 + 1\n",
        "        conv4_output_size = (conv3_output_size - 5) // 1 + 1\n",
        "        pool2_output_size = conv4_output_size // 2\n",
        "\n",
        "        self.fc1 = nn.Linear(128 * pool2_output_size, 5000)\n",
        "        self.fc2 = nn.Linear(5000, 1000)\n",
        "        self.fc3 = nn.Linear(1000, len(categories))\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = torch.relu(x)\n",
        "        x = self.pool1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = torch.relu(x)\n",
        "        x = self.conv3(x)\n",
        "        x = torch.relu(x)\n",
        "        x = self.conv4(x)\n",
        "        x = torch.relu(x)\n",
        "        x = self.pool2(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = torch.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "# 모델 초기화\n",
        "model = CNNModel().to(device)\n",
        "\n",
        "# 손실 함수 및 옵티마이저\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.0001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "WuubBwaK17LB"
      },
      "outputs": [],
      "source": [
        "# 모델 훈련\n",
        "def train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=10):\n",
        "    model.train()\n",
        "    for epoch in range(num_epochs):\n",
        "        running_loss = 0.0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        for inputs, labels in train_loader:\n",
        "            inputs, labels = inputs.unsqueeze(1).to(device), labels.to(device)  # 입력 형태를 [batch_size, 1, sequence_length]로 만듦\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "        val_loss, val_accuracy = evaluate_model(model, val_loader, criterion)\n",
        "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/total:.4f}, Accuracy: {100 * correct/total:.2f}%, Val Loss: {val_loss:.4f}, Val Accuracy: {val_accuracy:.2f}%')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "TdumqLwT17Nh"
      },
      "outputs": [],
      "source": [
        "# 모델 평가\n",
        "def evaluate_model(model, loader, criterion):\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in loader:\n",
        "            inputs, labels = inputs.unsqueeze(1).to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            val_loss += loss.item()\n",
        "\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    return val_loss / total, 100 * correct / total"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "PjSkuJTk17P_"
      },
      "outputs": [],
      "source": [
        "# 매그니튜드 기반 프루닝 함수\n",
        "def prune_by_magnitude(model, threshold):\n",
        "    for name, module in model.named_modules():\n",
        "        if isinstance(module, nn.Conv1d) or isinstance(module, nn.Linear):\n",
        "            prune.l1_unstructured(module, name='weight', amount=threshold)\n",
        "            prune.remove(module, 'weight')  # 프루닝 마스크 제거하고 실제 파라미터에 반영\n",
        "    print(f'Magnitude-based pruning with threshold: {threshold} applied.')\n",
        "\n",
        "# 1차 테일러 전개 기반 프루닝 함수\n",
        "def prune_by_taylor(model, threshold):\n",
        "    for name, module in model.named_modules():\n",
        "        if isinstance(module, nn.Conv1d) or isinstance(module, nn.Linear):\n",
        "            importance = torch.abs(module.weight * module.weight.grad)\n",
        "            mask = importance > threshold\n",
        "            with torch.no_grad():\n",
        "                module.weight[~mask] = 0  # 중요하지 않은 파라미터는 0으로 설정\n",
        "    print(f'Taylor expansion-based pruning with threshold: {threshold} applied.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "Ny4x-WRp17Sc"
      },
      "outputs": [],
      "source": [
        "# 모델 재훈련 (파인튜닝) 함수\n",
        "def fine_tune_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=5):\n",
        "    model.train()\n",
        "    for epoch in range(num_epochs):\n",
        "        running_loss = 0.0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        for inputs, labels in train_loader:\n",
        "            inputs, labels = inputs.unsqueeze(1).to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "        val_loss, val_accuracy = evaluate_model(model, val_loader, criterion)\n",
        "        print(f'Fine-tuning Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/total:.4f}, Accuracy: {100 * correct/total:.2f}%, Val Loss: {val_loss:.4f}, Val Accuracy: {val_accuracy:.2f}%')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bwVNTA-r17VB",
        "outputId": "327a8412-e899-4ad9-f392-090f4f809d28"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Loss: 0.0391, Accuracy: 49.92%, Val Loss: 0.0394, Val Accuracy: 50.00%\n",
            "Epoch [2/10], Loss: 0.0390, Accuracy: 50.00%, Val Loss: 0.0392, Val Accuracy: 50.00%\n",
            "Epoch [3/10], Loss: 0.0272, Accuracy: 65.22%, Val Loss: 0.0056, Val Accuracy: 94.15%\n",
            "Epoch [4/10], Loss: 0.0051, Accuracy: 95.52%, Val Loss: 0.0015, Val Accuracy: 99.81%\n",
            "Epoch [5/10], Loss: 0.0008, Accuracy: 99.83%, Val Loss: 0.0004, Val Accuracy: 100.00%\n",
            "Epoch [6/10], Loss: 0.0034, Accuracy: 97.44%, Val Loss: 0.0141, Val Accuracy: 76.56%\n",
            "Epoch [7/10], Loss: 0.0011, Accuracy: 99.02%, Val Loss: 0.0002, Val Accuracy: 100.00%\n",
            "Epoch [8/10], Loss: 0.0004, Accuracy: 99.78%, Val Loss: 0.0002, Val Accuracy: 100.00%\n",
            "Epoch [9/10], Loss: 0.0028, Accuracy: 97.66%, Val Loss: 0.0018, Val Accuracy: 99.00%\n",
            "Epoch [10/10], Loss: 0.0011, Accuracy: 99.14%, Val Loss: 0.0060, Val Accuracy: 91.59%\n"
          ]
        }
      ],
      "source": [
        "# 초기 훈련\n",
        "train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YVA4TM5D17XP",
        "outputId": "efae7006-25d0-4186-fbce-943eeb6b92ea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Magnitude-based pruning with threshold: 0.1 applied.\n"
          ]
        }
      ],
      "source": [
        "# 매그니튜드 기반 프루닝 적용\n",
        "magnitude_threshold = 0.1  # 매그니튜드 프루닝 임계값 설정\n",
        "prune_by_magnitude(model, magnitude_threshold)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nn5rqlIU17Zt",
        "outputId": "95c05e50-b481-47e7-c39f-d8d0b59d550f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tuning Epoch [1/5], Loss: 0.0025, Accuracy: 97.99%, Val Loss: 0.0012, Val Accuracy: 99.04%\n",
            "Fine-tuning Epoch [2/5], Loss: 0.0005, Accuracy: 99.70%, Val Loss: 0.0002, Val Accuracy: 99.93%\n",
            "Fine-tuning Epoch [3/5], Loss: 0.0001, Accuracy: 99.98%, Val Loss: 0.0001, Val Accuracy: 100.00%\n",
            "Fine-tuning Epoch [4/5], Loss: 0.0000, Accuracy: 100.00%, Val Loss: 0.0000, Val Accuracy: 100.00%\n",
            "Fine-tuning Epoch [5/5], Loss: 0.0006, Accuracy: 99.33%, Val Loss: 0.0000, Val Accuracy: 100.00%\n"
          ]
        }
      ],
      "source": [
        "# 매그니튜드 기반 프루닝 후 파인튜닝\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
        "fine_tune_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9cd6BtyL2qfk",
        "outputId": "d7730533-caaa-4dc5-9c36-210e1dd2c988"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Taylor expansion-based pruning with threshold: 1e-06 applied.\n"
          ]
        }
      ],
      "source": [
        "# 1차 테일러 전개 기반 프루닝 적용\n",
        "taylor_threshold = 0.00001  # 테일러 전개 프루닝 임계값 설정\n",
        "prune_by_taylor(model, taylor_threshold)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VOmOi4dO2qiA",
        "outputId": "3fb4a313-5b68-4b5d-dd71-e0de667612a7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tuning Epoch [1/5], Loss: 0.0117, Accuracy: 83.46%, Val Loss: 0.0004, Val Accuracy: 100.00%\n",
            "Fine-tuning Epoch [2/5], Loss: 0.0020, Accuracy: 99.21%, Val Loss: 0.1421, Val Accuracy: 50.00%\n",
            "Fine-tuning Epoch [3/5], Loss: 0.0021, Accuracy: 98.48%, Val Loss: 0.0003, Val Accuracy: 100.00%\n",
            "Fine-tuning Epoch [4/5], Loss: 0.0002, Accuracy: 100.00%, Val Loss: 0.0004, Val Accuracy: 99.56%\n",
            "Fine-tuning Epoch [5/5], Loss: 0.0059, Accuracy: 95.47%, Val Loss: 0.0022, Val Accuracy: 99.30%\n"
          ]
        }
      ],
      "source": [
        "# 테일러 전개 기반 프루닝 후 파인튜닝\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
        "fine_tune_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9KS8_tIM2qkf",
        "outputId": "d8fa4ad7-9d98-4a5a-e1b2-13c3121d8b25"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 0.0020, Test Accuracy: 99.96%\n"
          ]
        }
      ],
      "source": [
        "# 테스트 성능 확인\n",
        "test_loss, test_accuracy = evaluate_model(model, test_loader, criterion)\n",
        "print(f'Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.2f}%')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "GiKWZxBJ2qnC"
      },
      "outputs": [],
      "source": [
        "# 모델 저장\n",
        "torch.save(model.state_dict(), 'model.pth')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n3Njlehd2qpa",
        "outputId": "68cdfeb6-cfb9-40f1-f40e-85f09fd378cf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Size: 922.66 MB\n"
          ]
        }
      ],
      "source": [
        "# 모델 사이즈 확인\n",
        "model_size = os.path.getsize('model.pth') / (1024 * 1024)\n",
        "print(f\"Model Size: {model_size:.2f} MB\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xXnswIzQ2qrq",
        "outputId": "4540c71d-8d80-4208-d192-53ae33c8732f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of trainable parameters: 241868660\n"
          ]
        }
      ],
      "source": [
        "# 파라미터 수 확인\n",
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "total_params = count_parameters(model)\n",
        "print(f\"Total number of trainable parameters: {total_params}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i1lnUv6a17cD",
        "outputId": "33f42b95-6dd9-4fb4-e04c-642996c8081c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of non-zero weights: 48741362\n",
            "Total number of weights: 241868660\n",
            "Percentage of non-zero weights: 20.15%\n"
          ]
        }
      ],
      "source": [
        "# 비제로 가중치 계산 함수\n",
        "def count_nonzero_weights(model):\n",
        "    nonzero_count = 0\n",
        "    total_count = 0\n",
        "    for name, param in model.named_parameters():\n",
        "        if param.requires_grad:\n",
        "            nonzero_count += torch.sum(param != 0).item()  # 0이 아닌 가중치 수 계산\n",
        "            total_count += param.numel()  # 전체 가중치 수 계산\n",
        "    return nonzero_count, total_count\n",
        "\n",
        "# 비제로 가중치 수 계산\n",
        "nonzero_weights, total_weights = count_nonzero_weights(model)\n",
        "print(f\"Number of non-zero weights: {nonzero_weights}\")\n",
        "print(f\"Total number of weights: {total_weights}\")\n",
        "print(f\"Percentage of non-zero weights: {100 * nonzero_weights / total_weights:.2f}%\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "gpuType": "V28",
      "machine_shape": "hm",
      "provenance": [],
      "authorship_tag": "ABX9TyMgX0YXxDoBBiXo8JKwNB+k",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}