{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "V28",
      "authorship_tag": "ABX9TyPwgs9O9sSnYaHndB2C8L9X",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TheCaveOfAdullam/study3/blob/main/1017Test2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lIF8zvhPSWrv",
        "outputId": "08baf58f-07bc-4ab0-cd76-a63e124535ae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch_pruning"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3AxWAgQiVRw1",
        "outputId": "eaa312f2-04c6-4aeb-aa4c-a72ebb2dda7d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch_pruning\n",
            "  Downloading torch_pruning-1.4.3-py3-none-any.whl.metadata (29 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from torch_pruning) (2.4.0+cpu)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch_pruning) (1.26.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->torch_pruning) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->torch_pruning) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->torch_pruning) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->torch_pruning) (3.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->torch_pruning) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->torch_pruning) (2024.9.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->torch_pruning) (3.0.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->torch_pruning) (1.3.0)\n",
            "Downloading torch_pruning-1.4.3-py3-none-any.whl (62 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/62.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.9/62.9 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torch_pruning\n",
            "Successfully installed torch_pruning-1.4.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.utils as utils\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import torch.nn.utils.prune as prune\n",
        "import torch_pruning as tp"
      ],
      "metadata": {
        "id": "vn1A2eyoScnI"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 기본 경로 설정\n",
        "base_dir = '/content/drive/MyDrive/ship_motor10'\n",
        "categories = ['normal', 'fault_BB', 'fault_RI', 'fault_SM']\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# 데이터 로드 및 전처리 함수 정의\n",
        "class VibrationDataset(Dataset):\n",
        "    def __init__(self, base_dir, split, categories, transform=None):\n",
        "        self.X = []\n",
        "        self.y = []\n",
        "        self.transform = transform\n",
        "        split_dir = os.path.join(base_dir, split)\n",
        "        for category in categories:\n",
        "            category_dir = os.path.join(split_dir, category)\n",
        "            files = os.listdir(category_dir)\n",
        "            for file in files:\n",
        "                file_path = os.path.join(category_dir, file)\n",
        "                data = pd.read_csv(file_path, header=None).values\n",
        "                data = pd.to_numeric(data.flatten(), errors='coerce').reshape(-1, data.shape[1])\n",
        "                data = np.nan_to_num(data).astype('float32')  # NaN 값을 0으로 대체하고, float32로 변환\n",
        "                self.X.append(data)\n",
        "                self.y.append(category)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        X = self.X[idx]\n",
        "        y = self.y[idx]\n",
        "        X = X.reshape(-1)  # 마지막 차원을 시퀀스에 병합하여 [sequence_length]로 변환\n",
        "        return torch.tensor(X, dtype=torch.float32), y\n",
        "\n",
        "# 레이블 인코딩\n",
        "label_encoder = LabelEncoder()\n",
        "\n",
        "# 데이터셋 준비\n",
        "train_dataset = VibrationDataset(base_dir, 'train', categories)\n",
        "val_dataset = VibrationDataset(base_dir, 'validation', categories)\n",
        "test_dataset = VibrationDataset(base_dir, 'test', categories)\n",
        "\n",
        "# 레이블 인코딩 및 원-핫 인코딩\n",
        "y_train_encoded = label_encoder.fit_transform([y for _, y in train_dataset])\n",
        "y_val_encoded = label_encoder.transform([y for _, y in val_dataset])\n",
        "y_test_encoded = label_encoder.transform([y for _, y in test_dataset])\n",
        "\n",
        "# 데이터셋에 레이블 추가\n",
        "train_dataset.y = y_train_encoded\n",
        "val_dataset.y = y_val_encoded\n",
        "test_dataset.y = y_test_encoded\n",
        "\n",
        "# 데이터 로더\n",
        "batch_size = 32\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
      ],
      "metadata": {
        "id": "knKx7NabScpo"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CNNModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNNModel, self).__init__()\n",
        "        self.conv1 = nn.Conv1d(in_channels=1, out_channels=64, kernel_size=16, stride=16)\n",
        "        self.pool1 = nn.MaxPool1d(kernel_size=2, stride=2)\n",
        "        self.conv2 = nn.Conv1d(in_channels=64, out_channels=32, kernel_size=3, stride=1)\n",
        "        self.conv3 = nn.Conv1d(in_channels=32, out_channels=64, kernel_size=5, stride=1)\n",
        "        self.conv4 = nn.Conv1d(in_channels=64, out_channels=128, kernel_size=5, stride=1)\n",
        "        self.pool2 = nn.MaxPool1d(kernel_size=2, stride=2)\n",
        "\n",
        "        conv1_output_size = (24002 - 16) // 16 + 1\n",
        "        pool1_output_size = conv1_output_size // 2\n",
        "        conv2_output_size = (pool1_output_size - 3) // 1 + 1\n",
        "        conv3_output_size = (conv2_output_size - 5) // 1 + 1\n",
        "        conv4_output_size = (conv3_output_size - 5) // 1 + 1\n",
        "        pool2_output_size = conv4_output_size // 2\n",
        "\n",
        "        self.fc1 = nn.Linear(128 * pool2_output_size, 5000)\n",
        "        self.fc2 = nn.Linear(5000, 1000)\n",
        "        self.fc3 = nn.Linear(1000, len(categories))\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = torch.relu(x)\n",
        "        x = self.pool1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = torch.relu(x)\n",
        "        x = self.conv3(x)\n",
        "        x = torch.relu(x)\n",
        "        x = self.conv4(x)\n",
        "        x = torch.relu(x)\n",
        "        x = self.pool2(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = torch.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "feiT25FBScsI"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1차 테일러 전개 기반 비구조적 프루닝\n",
        "def prune_by_taylor(model, threshold=0.01):\n",
        "    for name, module in model.named_modules():\n",
        "        # Conv1d 레이어와 FC (Linear) 레이어 모두에 대해 적용\n",
        "        if isinstance(module, nn.Conv1d) or isinstance(module, nn.Linear):\n",
        "            if module.weight.grad is None:\n",
        "                raise ValueError(f\"Gradients not found for {name}. Run backward pass before pruning.\")\n",
        "\n",
        "            # 중요도 계산 (Taylor 기반)\n",
        "            importance = torch.abs(module.weight * module.weight.grad)\n",
        "            mask = importance > threshold\n",
        "            with torch.no_grad():\n",
        "                module.weight[~mask] = 0  # 중요도가 낮은 가중치 0으로 설정\n",
        "    print(f\"Taylor expansion-based pruning with threshold: {threshold} applied.\")\n",
        "\n",
        "# 0 비율 기반 필터 감지 및 구조적 프루닝 적용 함수\n",
        "def detect_and_apply_structural_pruning_with_zero_ratio(model, prune_threshold=0.7, example_inputs=None):\n",
        "    if example_inputs is None:\n",
        "        example_inputs = torch.randn(1, 1, 24002).to(next(model.parameters()).device)\n",
        "\n",
        "    # Dependency Graph 생성 (의존성 추적)\n",
        "    DG = tp.DependencyGraph().build_dependency(model, example_inputs=example_inputs)\n",
        "\n",
        "    total_pruned = 0\n",
        "    # Conv 및 FC 레이어 프루닝\n",
        "    for name, module in model.named_modules():\n",
        "        if isinstance(module, nn.Conv1d) or isinstance(module, nn.Linear):\n",
        "            # 각 필터 또는 뉴런에서 0 비율 계산\n",
        "            weight_data = module.weight.detach().cpu().numpy()\n",
        "            filter_zero_percentage = np.mean(weight_data == 0, axis=(1, 2) if isinstance(module, nn.Conv1d) else 1)\n",
        "            prune_indices = np.where(filter_zero_percentage >= prune_threshold)[0]\n",
        "\n",
        "            # 프루닝 대상 필터 또는 뉴런 제거\n",
        "            if len(prune_indices) > 0 and len(prune_indices) < module.weight.shape[0]:\n",
        "                pruning_group = None\n",
        "                if isinstance(module, nn.Conv1d):\n",
        "                    pruning_group = DG.get_pruning_group(module, tp.prune_conv_out_channels, idxs=prune_indices)\n",
        "                elif isinstance(module, nn.Linear):\n",
        "                    pruning_group = DG.get_pruning_group(module, tp.prune_linear_out_channels, idxs=prune_indices)\n",
        "\n",
        "                if pruning_group is not None:\n",
        "                    pruning_group.prune()  # 의존성 그래프를 통해 다음 레이어와의 연결을 조정\n",
        "                    total_pruned += len(prune_indices)\n",
        "                    print(f\"Pruned {len(prune_indices)} filters/neuron(s) from {name}.\")\n",
        "                else:\n",
        "                    print(f\"Skipping pruning for {name} as no pruning group was generated.\")\n",
        "            else:\n",
        "                print(f\"Skipping pruning for {name} as it would remove all filters/neuron(s).\")\n",
        "\n",
        "    print(f\"Structural pruning based on zero ratio applied. {total_pruned} filters/neuron(s) pruned in total.\")\n",
        "    return model"
      ],
      "metadata": {
        "id": "SNFe4xd6Scuu"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 학습 함수\n",
        "def train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=5, max_norm=1.0):\n",
        "    model.train()\n",
        "    for epoch in range(num_epochs):\n",
        "        running_loss = 0.0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        for inputs, labels in train_loader:\n",
        "            inputs, labels = inputs.unsqueeze(1).to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "\n",
        "            # 그래디언트 클리핑\n",
        "            utils.clip_grad_norm_(model.parameters(), max_norm)\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "        val_loss, val_accuracy = evaluate_model(model, val_loader, criterion)\n",
        "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/total:.4f}, Accuracy: {100 * correct/total:.2f}%, Val Loss: {val_loss:.4f}, Val Accuracy: {val_accuracy:.2f}%')\n",
        "\n",
        "    return model\n",
        "\n",
        "# 모델 평가 함수\n",
        "def evaluate_model(model, loader, criterion):\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in loader:\n",
        "            inputs, labels = inputs.unsqueeze(1).to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            val_loss += loss.item()\n",
        "\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    return val_loss / total, 100 * correct / total"
      ],
      "metadata": {
        "id": "3xLa6q_XScxf"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 프루닝 과정\n",
        "def prune_and_retrain(model, train_loader, val_loader, test_loader, criterion, device, optimizer_params, threshold_taylor=0.01, prune_threshold=0.7):\n",
        "    # 옵티마이저 설정\n",
        "    optimizer = optim.Adam(model.parameters(), **optimizer_params)\n",
        "\n",
        "    # 1차적으로 모델 학습\n",
        "    print(\"Initial training before pruning\")\n",
        "    model = train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=5)\n",
        "\n",
        "    # 1차 테일러 전개 기반 비구조적 프루닝\n",
        "    print(\"Step 1: Taylor expansion-based pruning\")\n",
        "    for inputs, labels in train_loader:\n",
        "        inputs, labels = inputs.unsqueeze(1).to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()  # 경사도 계산\n",
        "        break  # 경사도만 계산하므로 한 배치만 사용\n",
        "    prune_by_taylor(model, threshold_taylor)\n",
        "\n",
        "    # 재학습\n",
        "    optimizer = optim.Adam(model.parameters(), **optimizer_params)\n",
        "    model = train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=5)\n",
        "\n",
        "    # 구조적 프루닝 (0 비율이 70% 이상인 필터와 뉴런 제거)\n",
        "    print(\"Step 2: Structural pruning based on zero ratio\")\n",
        "    model = detect_and_apply_structural_pruning_with_zero_ratio(model, prune_threshold=prune_threshold)\n",
        "\n",
        "    # 다시 재학습\n",
        "    optimizer = optim.Adam(model.parameters(), **optimizer_params)\n",
        "    model = train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=5)\n",
        "\n",
        "    # 최종 테스트 평가\n",
        "    print(\"Final evaluation on the test set...\")\n",
        "    test_loss, test_accuracy = evaluate_model(model, test_loader, criterion)\n",
        "    print(f'Final Test Loss: {test_loss:.4f}, Final Test Accuracy: {test_accuracy:.2f}%')\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "YGhk4sPuSc0T"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 파라미터 설정 및 프루닝 실행\n",
        "model = CNNModel().to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer_params = {'lr': 0.0001, 'weight_decay': 1e-5}\n",
        "\n",
        "# 프루닝 및 재학습 실행\n",
        "model = prune_and_retrain(model, train_loader, val_loader, test_loader, criterion, device, optimizer_params, threshold_taylor=0.0001, prune_threshold=0.7)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_FjWOCgLSc2p",
        "outputId": "d10cab17-2d6c-4478-a99f-371a1d983905"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial training before pruning\n",
            "Epoch [1/5], Loss: 0.0391, Accuracy: 49.94%, Val Loss: 0.0393, Val Accuracy: 50.00%\n",
            "Epoch [2/5], Loss: 0.0390, Accuracy: 50.00%, Val Loss: 0.0392, Val Accuracy: 50.00%\n",
            "Epoch [3/5], Loss: 0.0333, Accuracy: 56.83%, Val Loss: 0.0185, Val Accuracy: 80.70%\n",
            "Epoch [4/5], Loss: 0.0146, Accuracy: 79.75%, Val Loss: 0.0109, Val Accuracy: 92.44%\n",
            "Epoch [5/5], Loss: 0.0083, Accuracy: 88.97%, Val Loss: 0.0401, Val Accuracy: 33.44%\n",
            "Step 1: Taylor expansion-based pruning\n",
            "Taylor expansion-based pruning with threshold: 0.0001 applied.\n",
            "Epoch [1/5], Loss: 0.0180, Accuracy: 82.40%, Val Loss: 0.0040, Val Accuracy: 97.11%\n",
            "Epoch [2/5], Loss: 0.0050, Accuracy: 93.87%, Val Loss: 0.0035, Val Accuracy: 95.44%\n",
            "Epoch [3/5], Loss: 0.0046, Accuracy: 94.33%, Val Loss: 0.0017, Val Accuracy: 98.41%\n",
            "Epoch [4/5], Loss: 0.0082, Accuracy: 90.22%, Val Loss: 0.0354, Val Accuracy: 70.63%\n",
            "Epoch [5/5], Loss: 0.0054, Accuracy: 93.38%, Val Loss: 0.0013, Val Accuracy: 98.26%\n",
            "Step 2: Structural pruning based on zero ratio\n",
            "Pruned 6 filters/neuron(s) from conv1.\n",
            "Pruned 3 filters/neuron(s) from conv2.\n",
            "Pruned 3 filters/neuron(s) from conv3.\n",
            "Pruned 8 filters/neuron(s) from conv4.\n",
            "Skipping pruning for fc1 as it would remove all filters/neuron(s).\n",
            "Pruned 352 filters/neuron(s) from fc2.\n",
            "Skipping pruning for fc3 as it would remove all filters/neuron(s).\n",
            "Structural pruning based on zero ratio applied. 372 filters/neuron(s) pruned in total.\n",
            "Epoch [1/5], Loss: 0.0077, Accuracy: 95.11%, Val Loss: 0.0006, Val Accuracy: 99.15%\n",
            "Epoch [2/5], Loss: 0.0077, Accuracy: 93.99%, Val Loss: 0.0001, Val Accuracy: 99.96%\n",
            "Epoch [3/5], Loss: 0.0032, Accuracy: 97.34%, Val Loss: 0.0003, Val Accuracy: 99.56%\n",
            "Epoch [4/5], Loss: 0.0010, Accuracy: 98.83%, Val Loss: 0.0000, Val Accuracy: 100.00%\n",
            "Epoch [5/5], Loss: 0.0020, Accuracy: 98.22%, Val Loss: 0.0000, Val Accuracy: 100.00%\n",
            "Final evaluation on the test set...\n",
            "Final Test Loss: 0.0001, Final Test Accuracy: 99.89%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 프루닝 및 재학습 후 모델 평가\n",
        "print(\"Final evaluation on the test set...\")\n",
        "test_loss, test_accuracy = evaluate_model(model, test_loader, criterion)\n",
        "print(f'Final Test Loss: {test_loss:.4f}, Final Test Accuracy: {test_accuracy:.2f}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZeU1WQhZSc5c",
        "outputId": "3b92119d-7a8c-46d1-e93f-261d1fc53726"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final evaluation on the test set...\n",
            "Final Test Loss: 0.0001, Final Test Accuracy: 99.89%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dxhNzmObSc78"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CcxNJSSrSc-_"
      },
      "execution_count": 10,
      "outputs": []
    }
  ]
}