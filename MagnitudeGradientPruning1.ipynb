{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "V28",
      "authorship_tag": "ABX9TyMMTtEfXneb1DOuyHx1R4F7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TheCaveOfAdullam/study3/blob/main/MagnitudeGradientPruning1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FZgfryOOBZIr",
        "outputId": "38e77048-229d-45db-eb1f-910a81f7654f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow_model_optimization"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-l4G55YrBb05",
        "outputId": "41bceda7-c3eb-4e7f-86eb-8037bd3fa03c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow_model_optimization\n",
            "  Downloading tensorflow_model_optimization-0.8.0-py2.py3-none-any.whl.metadata (904 bytes)\n",
            "Requirement already satisfied: absl-py~=1.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow_model_optimization) (1.4.0)\n",
            "Requirement already satisfied: dm-tree~=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow_model_optimization) (0.1.8)\n",
            "Requirement already satisfied: numpy~=1.23 in /usr/local/lib/python3.10/dist-packages (from tensorflow_model_optimization) (1.26.4)\n",
            "Requirement already satisfied: six~=1.14 in /usr/local/lib/python3.10/dist-packages (from tensorflow_model_optimization) (1.16.0)\n",
            "Downloading tensorflow_model_optimization-0.8.0-py2.py3-none-any.whl (242 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m242.5/242.5 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tensorflow_model_optimization\n",
            "Successfully installed tensorflow_model_optimization-0.8.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import tensorflow_model_optimization as tfmot"
      ],
      "metadata": {
        "id": "SiSDkSNIBggA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 로드 및 전처리 함수 정의\n",
        "def load_data(base_dir, split, categories):\n",
        "    X = []\n",
        "    y = []\n",
        "    split_dir = os.path.join(base_dir, split)\n",
        "    for category in categories:\n",
        "        category_dir = os.path.join(split_dir, category)\n",
        "        for file in os.listdir(category_dir):\n",
        "            file_path = os.path.join(category_dir, file)\n",
        "            data = pd.read_csv(file_path, header=None).values\n",
        "            data = pd.to_numeric(data.flatten(), errors='coerce').reshape(-1, data.shape[1])\n",
        "            data = np.nan_to_num(data).astype('float32')  # NaN 값을 0으로 대체하고, float32로 변환\n",
        "            X.append(data)\n",
        "            y.append(category)\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "# 기본 경로 및 카테고리 설정\n",
        "base_dir = '/content/drive/MyDrive/ship_motor10'\n",
        "categories = ['normal', 'fault_BB', 'fault_RI', 'fault_SM']\n",
        "\n",
        "# 데이터 로드\n",
        "X_train, y_train = load_data(base_dir, 'train', categories)\n",
        "X_val, y_val = load_data(base_dir, 'validation', categories)\n",
        "X_test, y_test = load_data(base_dir, 'test', categories)\n",
        "\n",
        "# 데이터 차원 변경 (CNN 입력 형식에 맞게)\n",
        "X_train = np.expand_dims(X_train, axis=-1)\n",
        "X_val = np.expand_dims(X_val, axis=-1)\n",
        "X_test = np.expand_dims(X_test, axis=-1)\n",
        "\n",
        "# 레이블 인코딩\n",
        "label_encoder = LabelEncoder()\n",
        "y_train_encoded = label_encoder.fit_transform(y_train)\n",
        "y_val_encoded = label_encoder.transform(y_val)\n",
        "y_test_encoded = label_encoder.transform(y_test)\n",
        "\n",
        "# 원-핫 인코딩\n",
        "y_train_categorical = tf.keras.utils.to_categorical(y_train_encoded)\n",
        "y_val_categorical = tf.keras.utils.to_categorical(y_val_encoded)\n",
        "y_test_categorical = tf.keras.utils.to_categorical(y_test_encoded)"
      ],
      "metadata": {
        "id": "VTq80HW6Bb3n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 정의\n",
        "model = models.Sequential([\n",
        "    layers.Conv1D(filters=64, kernel_size=16, strides=16, activation='relu', input_shape=(X_train.shape[1], X_train.shape[2])),\n",
        "    layers.MaxPooling1D(pool_size=2, strides=2),\n",
        "    layers.Conv1D(filters=32, kernel_size=3, strides=1, activation='relu'),\n",
        "    layers.Conv1D(filters=64, kernel_size=5, strides=1, activation='relu'),\n",
        "    layers.Conv1D(filters=128, kernel_size=5, strides=1, activation='relu'),\n",
        "    layers.MaxPooling1D(pool_size=2, strides=2),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(units=5000, activation='relu'),\n",
        "    layers.Dense(units=1000, activation='relu'),\n",
        "    layers.Dense(len(categories), activation='softmax')\n",
        "])\n",
        "\n",
        "# 모델 컴파일\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.0001, clipnorm=1.0)\n",
        "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "S8L68tBLBb7_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 훈련\n",
        "history = model.fit(X_train, y_train_categorical, epochs=10, validation_data=(X_val, y_val_categorical), batch_size=32)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aQOlfDGFBb_B",
        "outputId": "673a7028-7725-4c56-ac92-6d1e1e7aebe9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "394/394 [==============================] - 228s 575ms/step - loss: 0.9228 - accuracy: 0.6324 - val_loss: 0.4589 - val_accuracy: 0.8356\n",
            "Epoch 2/10\n",
            "394/394 [==============================] - 225s 571ms/step - loss: 0.4233 - accuracy: 0.8228 - val_loss: 0.0763 - val_accuracy: 1.0000\n",
            "Epoch 3/10\n",
            "394/394 [==============================] - 225s 572ms/step - loss: 0.1458 - accuracy: 0.9463 - val_loss: 0.0663 - val_accuracy: 0.9841\n",
            "Epoch 4/10\n",
            "394/394 [==============================] - 227s 576ms/step - loss: 0.0189 - accuracy: 0.9953 - val_loss: 0.0139 - val_accuracy: 0.9978\n",
            "Epoch 5/10\n",
            "394/394 [==============================] - 226s 573ms/step - loss: 0.0053 - accuracy: 0.9983 - val_loss: 0.0053 - val_accuracy: 0.9993\n",
            "Epoch 6/10\n",
            "394/394 [==============================] - 227s 575ms/step - loss: 4.9514e-04 - accuracy: 0.9999 - val_loss: 1.2045e-04 - val_accuracy: 1.0000\n",
            "Epoch 7/10\n",
            "394/394 [==============================] - 225s 570ms/step - loss: 0.0060 - accuracy: 0.9977 - val_loss: 3.4040e-05 - val_accuracy: 1.0000\n",
            "Epoch 8/10\n",
            "394/394 [==============================] - 226s 572ms/step - loss: 0.0036 - accuracy: 0.9985 - val_loss: 0.0425 - val_accuracy: 0.9826\n",
            "Epoch 9/10\n",
            "394/394 [==============================] - 225s 571ms/step - loss: 0.0043 - accuracy: 0.9987 - val_loss: 3.4779e-05 - val_accuracy: 1.0000\n",
            "Epoch 10/10\n",
            "394/394 [==============================] - 225s 572ms/step - loss: 8.2367e-04 - accuracy: 0.9998 - val_loss: 6.5231e-05 - val_accuracy: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 프루닝 적용 코드\n",
        "def magnitude_based_pruning(layer, sparsity):\n",
        "    \"\"\"매그니튜드 기반 프루닝\"\"\"\n",
        "    if hasattr(layer, 'kernel'):\n",
        "        weights, biases = layer.get_weights()\n",
        "        threshold = np.percentile(np.abs(weights), sparsity * 100)\n",
        "        pruned_weights = np.where(np.abs(weights) < threshold, 0, weights)\n",
        "        layer.set_weights([pruned_weights, biases])\n",
        "\n",
        "def gradient_sensitivity_pruning(layer, gradients, threshold_ratio):\n",
        "    \"\"\"변화도 기반 프루닝\"\"\"\n",
        "    if hasattr(layer, 'kernel'):\n",
        "        weights, biases = layer.get_weights()\n",
        "        gradient_sensitivity = np.abs(gradients)\n",
        "        threshold = np.percentile(gradient_sensitivity, threshold_ratio * 100)\n",
        "        pruned_weights = np.where(gradient_sensitivity < threshold, 0, weights)\n",
        "        layer.set_weights([pruned_weights, biases])\n",
        "\n",
        "def combined_pruning(model, X_val, y_val, magnitude_sparsity=0.5, gradient_threshold=0.2):\n",
        "    # 기울기 정보는 학습 과정에서 구해야 함\n",
        "    with tf.GradientTape() as tape:\n",
        "        logits = model(X_val, training=True)\n",
        "        loss_value = tf.keras.losses.categorical_crossentropy(y_val, logits)\n",
        "    gradients = tape.gradient(loss_value, model.trainable_variables)\n",
        "\n",
        "    gradient_index = 0\n",
        "    for layer in model.layers:\n",
        "        if hasattr(layer, 'kernel'):\n",
        "            # 1단계: 매그니튜드 기반 프루닝\n",
        "            magnitude_based_pruning(layer, magnitude_sparsity)\n",
        "            # 2단계: 변화도 기반 프루닝\n",
        "            gradient_shape = layer.get_weights()[0].shape\n",
        "            relevant_gradients = gradients[gradient_index].numpy().reshape(gradient_shape)\n",
        "            gradient_sensitivity_pruning(layer, relevant_gradients, gradient_threshold)\n",
        "            gradient_index += 2  # 각 레이어에 대해 커널과 바이어스가 있으므로 2씩 증가\n",
        "\n",
        "            # 바이어스가 없는 경우에 대한 처리\n",
        "            if len(layer.get_weights()) == 1:\n",
        "                gradient_index -= 1  # 인덱스 보정\n",
        "\n",
        "# 조합된 프루닝 수행\n",
        "combined_pruning(model, X_val, y_val_categorical, magnitude_sparsity=0.9, gradient_threshold=0.8)"
      ],
      "metadata": {
        "id": "BT67jsHFBcBf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 스트립 프루닝 적용\n",
        "model_stripped = tfmot.sparsity.keras.strip_pruning(model)"
      ],
      "metadata": {
        "id": "qoUVD-mVBcEH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 프루닝 후 재학습 (파인 튜닝)\n",
        "model_stripped.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "history_finetune = model_stripped.fit(X_train, y_train_categorical, epochs=5, validation_data=(X_val, y_val_categorical), batch_size=32)"
      ],
      "metadata": {
        "id": "1qGzKY3VBcGo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d72f9a83-e5d6-41f0-ef94-06c85f0d1889"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "394/394 [==============================] - 236s 596ms/step - loss: 1.2533 - accuracy: 0.4954 - val_loss: 1.2578 - val_accuracy: 0.5000\n",
            "Epoch 2/5\n",
            "394/394 [==============================] - 229s 582ms/step - loss: 1.2308 - accuracy: 0.5026 - val_loss: 1.0559 - val_accuracy: 0.5367\n",
            "Epoch 3/5\n",
            "394/394 [==============================] - 229s 582ms/step - loss: 0.3831 - accuracy: 0.8088 - val_loss: 0.1969 - val_accuracy: 0.9067\n",
            "Epoch 4/5\n",
            "394/394 [==============================] - 232s 590ms/step - loss: 0.2875 - accuracy: 0.8779 - val_loss: 0.1262 - val_accuracy: 0.9474\n",
            "Epoch 5/5\n",
            "394/394 [==============================] - 231s 587ms/step - loss: 0.1305 - accuracy: 0.9457 - val_loss: 0.2386 - val_accuracy: 0.9037\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 평가\n",
        "test_loss, test_accuracy = model_stripped.evaluate(X_test, y_test_categorical)\n",
        "print(f'Test accuracy after combined pruning, stripping, and fine-tuning: {test_accuracy}')"
      ],
      "metadata": {
        "id": "2UFTwXYQBcJI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce461b0d-d9cd-44fb-b885-6526f233d2ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "85/85 [==============================] - 4s 43ms/step - loss: 0.2035 - accuracy: 0.9281\n",
            "Test accuracy after combined pruning, stripping, and fine-tuning: 0.9281481504440308\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 프루닝 스트립 (추론 시 프루닝 마스크 제거)\n",
        "model_for_export = tfmot.sparsity.keras.strip_pruning(model_stripped)\n",
        "\n",
        "# 프루닝된 모델 저장\n",
        "model_for_export.save('pruned_model.h5')\n",
        "\n",
        "# 프루닝된 모델 사이즈 측정\n",
        "pruned_model_size = os.path.getsize('pruned_model.h5') / (1024 * 1024)\n",
        "print(f\"Pruned Model Size: {pruned_model_size:.2f} MB\")"
      ],
      "metadata": {
        "id": "cwfChyveGWfV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "562ff163-a38a-40c3-ee4c-4631723ded5e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pruned Model Size: 463.71 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 스트립 프루닝 후 모델 저장\n",
        "model_stripped.save('pruned_model_stripped.h5')"
      ],
      "metadata": {
        "id": "V9ew_VX3BcLh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_non_zero_weights(model):\n",
        "    total_weights = 0\n",
        "    non_zero_weights = 0\n",
        "    for layer in model.layers:\n",
        "        if hasattr(layer, 'kernel'):\n",
        "            weights, biases = layer.get_weights()\n",
        "            total_weights += np.prod(weights.shape) + np.prod(biases.shape)\n",
        "            non_zero_weights += np.count_nonzero(weights) + np.count_nonzero(biases)\n",
        "    return non_zero_weights, total_weights\n",
        "\n",
        "non_zero_weights_after, total_weights_after = calculate_non_zero_weights(model_stripped)\n",
        "print(f\"After pruning: Non-zero weights = {non_zero_weights_after}, Total weights = {total_weights_after}\")\n",
        "print(f\"Final non-zero weight ratio: {non_zero_weights_after / total_weights_after:.4f}\")"
      ],
      "metadata": {
        "id": "YHvWwQp3BcQx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4177fff8-1f01-4d2f-a473-51bbcab35971"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "After pruning: Non-zero weights = 40979060, Total weights = 121549684\n",
            "Final non-zero weight ratio: 0.3371\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6KT4C_qbBcTI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}