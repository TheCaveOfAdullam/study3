{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "V28",
      "authorship_tag": "ABX9TyNyc0e4Ao8ZvZPj8GKsfsHG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TheCaveOfAdullam/study3/blob/main/TaylorTest3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Google Drive 연결 및 필요한 라이브러리 불러오기\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wULu0u_fixbH",
        "outputId": "bd5f6c1b-0ae0-494d-ef1f-9c3dbe72d394"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "xtWOtBgJirLC"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from sklearn.preprocessing import LabelEncoder"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 기본 경로 설정\n",
        "base_dir = '/content/drive/MyDrive/ship_motor10'\n",
        "categories = ['normal', 'fault_BB', 'fault_RI', 'fault_SM']\n",
        "\n",
        "# 데이터 로드 및 전처리 함수 정의\n",
        "def load_data(base_dir, split):\n",
        "    X = []\n",
        "    y = []\n",
        "    split_dir = os.path.join(base_dir, split)\n",
        "    for category in categories:\n",
        "        category_dir = os.path.join(split_dir, category)\n",
        "        for file in os.listdir(category_dir):\n",
        "            file_path = os.path.join(category_dir, file)\n",
        "            data = pd.read_csv(file_path, header=None).values\n",
        "            data = pd.to_numeric(data.flatten(), errors='coerce').reshape(-1, data.shape[1])\n",
        "            data = np.nan_to_num(data).astype('float32')  # NaN 값을 0으로 대체하고, float32로 변환\n",
        "            X.append(data)\n",
        "            y.append(category)\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "# 데이터 로드\n",
        "X_train, y_train = load_data(base_dir, 'train')\n",
        "X_val, y_val = load_data(base_dir, 'validation')\n",
        "X_test, y_test = load_data(base_dir, 'test')\n",
        "\n",
        "# 데이터 차원 변경 (CNN 입력 형식에 맞게)\n",
        "X_train = np.expand_dims(X_train, axis=-1)\n",
        "X_val = np.expand_dims(X_val, axis=-1)\n",
        "X_test = np.expand_dims(X_test, axis=-1)\n",
        "\n",
        "# 레이블 인코딩\n",
        "label_encoder = LabelEncoder()\n",
        "y_train_encoded = label_encoder.fit_transform(y_train)\n",
        "y_val_encoded = label_encoder.transform(y_val)\n",
        "y_test_encoded = label_encoder.transform(y_test)\n",
        "\n",
        "# 원-핫 인코딩\n",
        "y_train_categorical = tf.keras.utils.to_categorical(y_train_encoded)\n",
        "y_val_categorical = tf.keras.utils.to_categorical(y_val_encoded)\n",
        "y_test_categorical = tf.keras.utils.to_categorical(y_test_encoded)"
      ],
      "metadata": {
        "id": "ugQRGtgpizeW"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 정의\n",
        "model = models.Sequential()\n",
        "\n",
        "# Conv1 레이어\n",
        "model.add(layers.Conv1D(filters=64, kernel_size=16, strides=16, activation='relu', input_shape=(X_train.shape[1], X_train.shape[2])))\n",
        "# Pool1 레이어\n",
        "model.add(layers.MaxPooling1D(pool_size=2, strides=2))\n",
        "\n",
        "# Conv2 레이어\n",
        "model.add(layers.Conv1D(filters=32, kernel_size=3, strides=1, activation='relu'))\n",
        "\n",
        "# Conv3 레이어\n",
        "model.add(layers.Conv1D(filters=64, kernel_size=5, strides=1, activation='relu'))\n",
        "\n",
        "# Conv4 레이어\n",
        "model.add(layers.Conv1D(filters=128, kernel_size=5, strides=1, activation='relu'))\n",
        "\n",
        "# Pool2 레이어\n",
        "model.add(layers.MaxPooling1D(pool_size=2, strides=2))\n",
        "\n",
        "# Flatten 레이어\n",
        "model.add(layers.Flatten())\n",
        "\n",
        "# FC1 레이어\n",
        "model.add(layers.Dense(units=5000, activation='relu'))\n",
        "\n",
        "# FC2 레이어\n",
        "model.add(layers.Dense(units=1000, activation='relu'))\n",
        "\n",
        "# Output 레이어\n",
        "model.add(layers.Dense(len(categories), activation='softmax'))\n",
        "\n",
        "# 모델 컴파일\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# 모델 요약 출력\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KRGcAA2pizhW",
        "outputId": "ee99b3e0-603d-451f-ab97-808bde2d5da6"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d (Conv1D)             (None, 750, 64)           2112      \n",
            "                                                                 \n",
            " max_pooling1d (MaxPooling1  (None, 375, 64)           0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " conv1d_1 (Conv1D)           (None, 373, 32)           6176      \n",
            "                                                                 \n",
            " conv1d_2 (Conv1D)           (None, 369, 64)           10304     \n",
            "                                                                 \n",
            " conv1d_3 (Conv1D)           (None, 365, 128)          41088     \n",
            "                                                                 \n",
            " max_pooling1d_1 (MaxPoolin  (None, 182, 128)          0         \n",
            " g1D)                                                            \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 23296)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 5000)              116485000 \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1000)              5001000   \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 4)                 4004      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 121549684 (463.68 MB)\n",
            "Trainable params: 121549684 (463.68 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 훈련\n",
        "history = model.fit(X_train, y_train_categorical, epochs=10, validation_data=(X_val, y_val_categorical))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e3-_mQS8izj-",
        "outputId": "ad4b1ceb-3b4f-49f3-a7c8-f8282df8172f"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "394/394 [==============================] - 203s 513ms/step - loss: 0.9788 - accuracy: 0.6182 - val_loss: 0.1491 - val_accuracy: 0.9467\n",
            "Epoch 2/10\n",
            "394/394 [==============================] - 199s 505ms/step - loss: 0.0217 - accuracy: 0.9935 - val_loss: 0.0025 - val_accuracy: 1.0000\n",
            "Epoch 3/10\n",
            "394/394 [==============================] - 202s 512ms/step - loss: 0.0592 - accuracy: 0.9859 - val_loss: 0.4592 - val_accuracy: 0.8133\n",
            "Epoch 4/10\n",
            "394/394 [==============================] - 204s 517ms/step - loss: 0.1577 - accuracy: 0.9604 - val_loss: 0.0251 - val_accuracy: 0.9956\n",
            "Epoch 5/10\n",
            "394/394 [==============================] - 201s 511ms/step - loss: 0.0072 - accuracy: 0.9980 - val_loss: 2.6239e-04 - val_accuracy: 1.0000\n",
            "Epoch 6/10\n",
            "394/394 [==============================] - 202s 512ms/step - loss: 0.0046 - accuracy: 0.9989 - val_loss: 2.2455e-04 - val_accuracy: 1.0000\n",
            "Epoch 7/10\n",
            "394/394 [==============================] - 201s 509ms/step - loss: 0.0125 - accuracy: 0.9971 - val_loss: 8.6469e-05 - val_accuracy: 1.0000\n",
            "Epoch 8/10\n",
            "394/394 [==============================] - 200s 508ms/step - loss: 0.0031 - accuracy: 0.9993 - val_loss: 2.5322e-04 - val_accuracy: 1.0000\n",
            "Epoch 9/10\n",
            "394/394 [==============================] - 200s 507ms/step - loss: 0.0013 - accuracy: 0.9998 - val_loss: 2.5098e-04 - val_accuracy: 1.0000\n",
            "Epoch 10/10\n",
            "394/394 [==============================] - 200s 507ms/step - loss: 0.0204 - accuracy: 0.9960 - val_loss: 0.1027 - val_accuracy: 0.9526\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 평가 (훈련 후)\n",
        "test_loss, test_accuracy = model.evaluate(X_test, y_test_categorical)\n",
        "print(f'Test accuracy before pruning: {test_accuracy}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n8gdsFmVizme",
        "outputId": "0aa87413-7fe6-49f3-f16d-08000a0bda72"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "85/85 [==============================] - 3s 38ms/step - loss: 0.1222 - accuracy: 0.9478\n",
            "Test accuracy before pruning: 0.9477777481079102\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 원본 모델 저장\n",
        "model.save('model.h5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pLyBTCzzizpG",
        "outputId": "03d942dd-15c6-486f-fdf4-4590102dd1f8"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 사이즈 측정\n",
        "model_size = os.path.getsize('model.h5') / (1024 * 1024)\n",
        "print(f\"Model Size before pruning: {model_size:.2f} MB\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4DSFsII3izru",
        "outputId": "a0ccef62-77e7-486b-90ea-8380731c4944"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Size before pruning: 1391.09 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 프루닝 전 전체 가중치 수와 0이 아닌 가중치 수를 계산\n",
        "total_weights = 0\n",
        "non_zero_weights = 0\n",
        "for weight in model.trainable_variables:\n",
        "    w = weight.numpy()\n",
        "    total_weights += w.size\n",
        "    non_zero_weights += np.count_nonzero(w)\n",
        "print(f\"Before pruning: Non-zero weights = {non_zero_weights}, Total weights = {total_weights}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "326d1fQoizux",
        "outputId": "eb235bac-8b36-499c-a852-a65fe8cd8cbe"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Before pruning: Non-zero weights = 121549677, Total weights = 121549684\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === 테일러 전개 기반 프루닝 구현 ===\n",
        "def taylor_pruning(model, X_sample, y_sample, pruning_threshold):\n",
        "    # 손실에 대한 가중치의 변화도 계산\n",
        "    with tf.GradientTape() as tape:\n",
        "        predictions = model(X_sample)\n",
        "        loss = tf.keras.losses.categorical_crossentropy(y_sample, predictions)\n",
        "    gradients = tape.gradient(loss, model.trainable_variables)\n",
        "\n",
        "    # 중요도 계산: |w_i * grad_w_i|\n",
        "    importance_scores = []\n",
        "    weight_tensors = []\n",
        "    grad_tensors = []\n",
        "    for weight, grad in zip(model.trainable_variables, gradients):\n",
        "        # 편향(bias) 제외 (필요한 경우)\n",
        "        if 'bias' in weight.name:\n",
        "            continue\n",
        "        if weight is not None and grad is not None:\n",
        "            importance = tf.abs(weight * grad)\n",
        "            importance_scores.extend(importance.numpy().flatten())\n",
        "            weight_tensors.append(weight)\n",
        "            grad_tensors.append(grad)\n",
        "\n",
        "    # 중요도 점수를 NumPy 배열로 변환\n",
        "    all_scores = np.array(importance_scores)\n",
        "\n",
        "    # 중요도 점수 통계 출력\n",
        "    print(f\"Importance Scores - min: {all_scores.min()}, max: {all_scores.max()}, mean: {all_scores.mean()}\")\n",
        "\n",
        "    # 프루닝 임계값 출력\n",
        "    print(f\"Pruning Threshold (manually set): {pruning_threshold}\")\n",
        "\n",
        "    # 임계값 이하의 가중치 프루닝\n",
        "    for weight, grad in zip(weight_tensors, grad_tensors):\n",
        "        importance = tf.abs(weight * grad)\n",
        "        mask = tf.cast(importance >= pruning_threshold, weight.dtype)\n",
        "        pruned_weight = weight * mask\n",
        "        weight.assign(pruned_weight)\n",
        "\n",
        "# 변화도 계산을 위한 샘플 배치 사용\n",
        "X_sample = X_train\n",
        "y_sample = y_train_categorical"
      ],
      "metadata": {
        "id": "BTMM6mQWizy-"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 프루닝 임계값 직접 설정\n",
        "pruning_threshold = 0.00001  # 직접 임계값 설정\n",
        "\n",
        "taylor_pruning(model, X_sample, y_sample, pruning_threshold=pruning_threshold)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "26ItdRitiz1m",
        "outputId": "d4d1b112-5ce4-4e44-c806-96230e840aae"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Importance Scores - min: 0.0, max: 569.6116333007812, mean: 0.0010790671221911907\n",
            "Pruning Threshold (manually set): 1e-05\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 프루닝 후 가중치 상태 확인\n",
        "total_weights_after = 0\n",
        "non_zero_weights_after = 0\n",
        "for weight in model.trainable_variables:\n",
        "    w = weight.numpy()\n",
        "    total_weights_after += w.size\n",
        "    non_zero_weights_after += np.count_nonzero(w)\n",
        "print(f\"After pruning: Non-zero weights = {non_zero_weights_after}, Total weights = {total_weights_after}\")\n",
        "print(f\"Final non-zero weight ratio: {non_zero_weights_after / total_weights_after:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yhKxRlHHiz4O",
        "outputId": "f0e076d7-c0e1-494e-d6fd-e8dae0cefb6d"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "After pruning: Non-zero weights = 2165683, Total weights = 121549684\n",
            "Final non-zero weight ratio: 0.0178\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 각 레이어별로 0의 비율 출력\n",
        "for layer in model.layers:\n",
        "    weights = layer.get_weights()\n",
        "    if len(weights) > 0:\n",
        "        weight = weights[0]\n",
        "        zero_count = np.sum(weight == 0)\n",
        "        total_count = weight.size\n",
        "        zero_ratio = (zero_count / total_count) * 100\n",
        "        print(f\"Layer {layer.name}: {zero_ratio:.2f}% of weights are zero.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FEXZ0cMJjKzX",
        "outputId": "99af9e40-f719-4363-8906-cfdd11a46751"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layer conv1d: 45.90% of weights are zero.\n",
            "Layer conv1d_1: 73.19% of weights are zero.\n",
            "Layer conv1d_2: 77.24% of weights are zero.\n",
            "Layer conv1d_3: 89.07% of weights are zero.\n",
            "Layer dense: 98.38% of weights are zero.\n",
            "Layer dense_1: 94.78% of weights are zero.\n",
            "Layer dense_2: 69.97% of weights are zero.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 프루닝된 모델 평가\n",
        "test_loss, test_accuracy = model.evaluate(X_test, y_test_categorical)\n",
        "print(f'Test accuracy after pruning: {test_accuracy}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7eqeE541jK2P",
        "outputId": "1cd01e43-f9d7-4b9a-fd88-d56d685cbfa6"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "85/85 [==============================] - 3s 38ms/step - loss: 0.1227 - accuracy: 0.9478\n",
            "Test accuracy after pruning: 0.9477777481079102\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 재컴파일 (필요한 경우)\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "kCx-7M3ujK4y"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 미세조정 훈련\n",
        "fine_tune_epochs = 10\n",
        "history_finetune = model.fit(X_train, y_train_categorical, epochs=fine_tune_epochs, validation_data=(X_val, y_val_categorical))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C8CJNifwjK7c",
        "outputId": "b2f3193f-1e49-4984-9b62-ca225bcddf38"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "394/394 [==============================] - 206s 518ms/step - loss: 0.0551 - accuracy: 0.9875 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 2/10\n",
            "394/394 [==============================] - 201s 509ms/step - loss: 0.0039 - accuracy: 0.9992 - val_loss: 1.8683e-04 - val_accuracy: 1.0000\n",
            "Epoch 3/10\n",
            "394/394 [==============================] - 202s 512ms/step - loss: 5.8661e-05 - accuracy: 1.0000 - val_loss: 7.8689e-05 - val_accuracy: 1.0000\n",
            "Epoch 4/10\n",
            "394/394 [==============================] - 203s 515ms/step - loss: 3.9509e-05 - accuracy: 1.0000 - val_loss: 7.4252e-05 - val_accuracy: 1.0000\n",
            "Epoch 5/10\n",
            "394/394 [==============================] - 202s 512ms/step - loss: 0.2224 - accuracy: 0.9787 - val_loss: 0.0105 - val_accuracy: 0.9989\n",
            "Epoch 6/10\n",
            "394/394 [==============================] - 204s 518ms/step - loss: 7.6760e-04 - accuracy: 0.9999 - val_loss: 6.9323e-05 - val_accuracy: 1.0000\n",
            "Epoch 7/10\n",
            "394/394 [==============================] - 206s 522ms/step - loss: 4.5478e-05 - accuracy: 1.0000 - val_loss: 2.8514e-05 - val_accuracy: 1.0000\n",
            "Epoch 8/10\n",
            "394/394 [==============================] - 204s 519ms/step - loss: 1.5715e-05 - accuracy: 1.0000 - val_loss: 7.1362e-05 - val_accuracy: 1.0000\n",
            "Epoch 9/10\n",
            "394/394 [==============================] - 204s 519ms/step - loss: 9.4653e-06 - accuracy: 1.0000 - val_loss: 2.0372e-05 - val_accuracy: 1.0000\n",
            "Epoch 10/10\n",
            "394/394 [==============================] - 202s 512ms/step - loss: 6.2677e-06 - accuracy: 1.0000 - val_loss: 1.1104e-05 - val_accuracy: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 재학습 후 모델 평가\n",
        "test_loss, test_accuracy = model.evaluate(X_test, y_test_categorical)\n",
        "print(f'Test accuracy after fine-tuning: {test_accuracy}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9cq9u9EhjK-B",
        "outputId": "485736c6-2b0c-44a2-b31c-5c2bc6abce39"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "85/85 [==============================] - 3s 38ms/step - loss: 1.1045e-05 - accuracy: 1.0000\n",
            "Test accuracy after fine-tuning: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 재학습된 모델 저장\n",
        "model.save('model_pruned_finetuned.h5')"
      ],
      "metadata": {
        "id": "K2vanLOnjLAe"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 재학습된 모델 사이즈 측정\n",
        "model_size = os.path.getsize('model_pruned_finetuned.h5') / (1024 * 1024)\n",
        "print(f\"Model Size after fine-tuning: {model_size:.2f} MB\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wa2udjRPjLEo",
        "outputId": "8e44b992-7633-44a5-995b-b8680ae2abca"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Size after fine-tuning: 1391.09 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 프루닝 후 가중치 상태 확인\n",
        "total_weights_after = 0\n",
        "non_zero_weights_after = 0\n",
        "for weight in model.trainable_variables:\n",
        "    w = weight.numpy()\n",
        "    total_weights_after += w.size\n",
        "    non_zero_weights_after += np.count_nonzero(w)\n",
        "print(f\"After pruning: Non-zero weights = {non_zero_weights_after}, Total weights = {total_weights_after}\")\n",
        "print(f\"Final non-zero weight ratio: {non_zero_weights_after / total_weights_after:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JVtPijZLjYrY",
        "outputId": "50382448-1156-4918-8555-ca0618b438e9"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "After pruning: Non-zero weights = 8756519, Total weights = 121549684\n",
            "Final non-zero weight ratio: 0.0720\n"
          ]
        }
      ]
    }
  ]
}