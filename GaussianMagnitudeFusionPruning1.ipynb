{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "V28",
      "authorship_tag": "ABX9TyNSePypV2dnZXLcLt2hyTGB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TheCaveOfAdullam/study3/blob/main/GaussianMagnitudeFusionPruning1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Y8mxrs75QSz",
        "outputId": "031687ff-a67f-4cd9-deb2-7d85bcf25dca"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow_model_optimization"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EA0ASo8O5qbC",
        "outputId": "c0004721-a5a7-4fe0-bdfb-1ae9609c595b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow_model_optimization\n",
            "  Downloading tensorflow_model_optimization-0.8.0-py2.py3-none-any.whl.metadata (904 bytes)\n",
            "Requirement already satisfied: absl-py~=1.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow_model_optimization) (1.4.0)\n",
            "Requirement already satisfied: dm-tree~=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow_model_optimization) (0.1.8)\n",
            "Requirement already satisfied: numpy~=1.23 in /usr/local/lib/python3.10/dist-packages (from tensorflow_model_optimization) (1.26.4)\n",
            "Requirement already satisfied: six~=1.14 in /usr/local/lib/python3.10/dist-packages (from tensorflow_model_optimization) (1.16.0)\n",
            "Downloading tensorflow_model_optimization-0.8.0-py2.py3-none-any.whl (242 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m242.5/242.5 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tensorflow_model_optimization\n",
            "Successfully installed tensorflow_model_optimization-0.8.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "SI83ISJZ5PMF"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from scipy.stats import norm\n",
        "import tensorflow_model_optimization as tfmot"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 기본 경로 설정\n",
        "base_dir = '/content/drive/MyDrive/ship_motor10'\n",
        "categories = ['normal', 'fault_BB', 'fault_RI', 'fault_SM']\n",
        "\n",
        "# 데이터 로드 및 전처리 함수 정의\n",
        "def load_data(base_dir, split):\n",
        "    X = []\n",
        "    y = []\n",
        "    split_dir = os.path.join(base_dir, split)\n",
        "    for category in categories:\n",
        "        category_dir = os.path.join(split_dir, category)\n",
        "        for file in os.listdir(category_dir):\n",
        "            file_path = os.path.join(category_dir, file)\n",
        "            data = pd.read_csv(file_path, header=None).values\n",
        "            data = pd.to_numeric(data.flatten(), errors='coerce').reshape(-1, data.shape[1])\n",
        "            data = np.nan_to_num(data).astype('float32')  # NaN 값을 0으로 대체하고, float32로 변환\n",
        "            X.append(data)\n",
        "            y.append(category)\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "# 데이터 로드\n",
        "X_train, y_train = load_data(base_dir, 'train')\n",
        "X_val, y_val = load_data(base_dir, 'validation')\n",
        "X_test, y_test = load_data(base_dir, 'test')\n",
        "\n",
        "# 데이터 차원 변경 (CNN 입력 형식에 맞게)\n",
        "X_train = np.expand_dims(X_train, axis=-1)\n",
        "X_val = np.expand_dims(X_val, axis=-1)\n",
        "X_test = np.expand_dims(X_test, axis=-1)\n",
        "\n",
        "# 레이블 인코딩\n",
        "label_encoder = LabelEncoder()\n",
        "y_train_encoded = label_encoder.fit_transform(y_train)\n",
        "y_val_encoded = label_encoder.transform(y_val)\n",
        "y_test_encoded = label_encoder.transform(y_test)\n",
        "\n",
        "# 원-핫 인코딩\n",
        "y_train_categorical = tf.keras.utils.to_categorical(y_train_encoded, num_classes=len(categories))\n",
        "y_val_categorical = tf.keras.utils.to_categorical(y_val_encoded, num_classes=len(categories))\n",
        "y_test_categorical = tf.keras.utils.to_categorical(y_test_encoded, num_classes=len(categories))\n"
      ],
      "metadata": {
        "id": "vaJg24LF5Sah"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 정의\n",
        "model = models.Sequential()\n",
        "\n",
        "# Conv1 레이어\n",
        "model.add(layers.Conv1D(filters=64, kernel_size=16, strides=16, activation='relu', input_shape=(X_train.shape[1], X_train.shape[2])))\n",
        "# Pool1 레이어\n",
        "model.add(layers.MaxPooling1D(pool_size=2, strides=2))\n",
        "\n",
        "# Conv2 레이어\n",
        "model.add(layers.Conv1D(filters=32, kernel_size=3, strides=1, activation='relu'))\n",
        "\n",
        "# Conv3 레이어\n",
        "model.add(layers.Conv1D(filters=64, kernel_size=5, strides=1, activation='relu'))\n",
        "\n",
        "# Conv4 레이어\n",
        "model.add(layers.Conv1D(filters=128, kernel_size=5, strides=1, activation='relu'))\n",
        "\n",
        "# Pool2 레이어\n",
        "model.add(layers.MaxPooling1D(pool_size=2, strides=2))\n",
        "\n",
        "# Flatten 레이어\n",
        "model.add(layers.Flatten())\n",
        "\n",
        "# FC1 레이어\n",
        "model.add(layers.Dense(units=5000, activation='relu'))\n",
        "\n",
        "# FC2 레이어\n",
        "model.add(layers.Dense(units=1000, activation='relu'))\n",
        "\n",
        "# Output 레이어\n",
        "model.add(layers.Dense(len(categories), activation='softmax'))\n",
        "\n",
        "# 아담 옵티마이저 학습률 조정\n",
        "# optimizer = tf.keras.optimizers.Adam(learning_rate=0.0001, clipnorm=1.0)\n",
        "\n",
        "# 모델 컴파일\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# 모델 요약 출력\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B9ugadwl5SdL",
        "outputId": "12b0d557-2601-46e1-92cc-147601eeb69a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d_4 (Conv1D)           (None, 750, 64)           2112      \n",
            "                                                                 \n",
            " max_pooling1d_2 (MaxPoolin  (None, 375, 64)           0         \n",
            " g1D)                                                            \n",
            "                                                                 \n",
            " conv1d_5 (Conv1D)           (None, 373, 32)           6176      \n",
            "                                                                 \n",
            " conv1d_6 (Conv1D)           (None, 369, 64)           10304     \n",
            "                                                                 \n",
            " conv1d_7 (Conv1D)           (None, 365, 128)          41088     \n",
            "                                                                 \n",
            " max_pooling1d_3 (MaxPoolin  (None, 182, 128)          0         \n",
            " g1D)                                                            \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 23296)             0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 5000)              116485000 \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 1000)              5001000   \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 4)                 4004      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 121549684 (463.68 MB)\n",
            "Trainable params: 121549684 (463.68 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 훈련\n",
        "history = model.fit(X_train, y_train_categorical, epochs=10, validation_data=(X_val, y_val_categorical))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x-k7-ins5Sfx",
        "outputId": "a8dab8fe-a7a0-4d03-ee09-4652c01a0984"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "394/394 [==============================] - 197s 497ms/step - loss: 1.0383 - accuracy: 0.5944 - val_loss: 0.1744 - val_accuracy: 0.9244\n",
            "Epoch 2/10\n",
            "394/394 [==============================] - 195s 495ms/step - loss: 0.1319 - accuracy: 0.9571 - val_loss: 0.0987 - val_accuracy: 0.9637\n",
            "Epoch 3/10\n",
            "394/394 [==============================] - 196s 498ms/step - loss: 0.0355 - accuracy: 0.9881 - val_loss: 0.0360 - val_accuracy: 0.9900\n",
            "Epoch 4/10\n",
            "394/394 [==============================] - 197s 501ms/step - loss: 0.0803 - accuracy: 0.9714 - val_loss: 0.0422 - val_accuracy: 0.9867\n",
            "Epoch 5/10\n",
            "394/394 [==============================] - 198s 502ms/step - loss: 0.0181 - accuracy: 0.9947 - val_loss: 0.0018 - val_accuracy: 0.9996\n",
            "Epoch 6/10\n",
            "394/394 [==============================] - 196s 498ms/step - loss: 0.0317 - accuracy: 0.9925 - val_loss: 0.0074 - val_accuracy: 0.9993\n",
            "Epoch 7/10\n",
            "394/394 [==============================] - 197s 500ms/step - loss: 0.0110 - accuracy: 0.9969 - val_loss: 5.8513e-04 - val_accuracy: 0.9996\n",
            "Epoch 8/10\n",
            "394/394 [==============================] - 197s 499ms/step - loss: 0.0042 - accuracy: 0.9988 - val_loss: 0.0014 - val_accuracy: 0.9996\n",
            "Epoch 9/10\n",
            "394/394 [==============================] - 198s 502ms/step - loss: 0.3342 - accuracy: 0.9117 - val_loss: 0.0664 - val_accuracy: 0.9974\n",
            "Epoch 10/10\n",
            "394/394 [==============================] - 197s 500ms/step - loss: 0.0328 - accuracy: 0.9912 - val_loss: 0.0083 - val_accuracy: 0.9978\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 평가\n",
        "test_loss, test_accuracy = model.evaluate(X_test, y_test_categorical)\n",
        "print(f'Test accuracy: {test_accuracy}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8prkyxzK5SiJ",
        "outputId": "b6ec92c4-ca2d-48f5-b027-1e5c83c2b574"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "85/85 [==============================] - 3s 40ms/step - loss: 0.0234 - accuracy: 0.9911\n",
            "Test accuracy: 0.9911110997200012\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 원본 모델 저장\n",
        "model.save('model.h5')\n",
        "\n",
        "# 모델 사이즈 측정\n",
        "model_size = os.path.getsize('model.h5') / (1024 * 1024)\n",
        "print(f\"Model Size: {model_size:.2f} MB\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qoT8Pctd5Skx",
        "outputId": "c82fbd12-e543-4420-83c9-b1406bc40e87"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Size: 1391.09 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 가중치 비율 계산 함수\n",
        "def calculate_non_zero_weights(model):\n",
        "    total_weights = 0\n",
        "    non_zero_weights = 0\n",
        "    for layer in model.layers:\n",
        "        if hasattr(layer, 'kernel'):\n",
        "            weights = layer.get_weights()[0]\n",
        "            total_weights += weights.size\n",
        "            non_zero_weights += np.count_nonzero(weights)\n",
        "    return non_zero_weights, total_weights\n",
        "\n",
        "# 프루닝 전 가중치 비율 계산\n",
        "non_zero_weights_before, total_weights_before = calculate_non_zero_weights(model)\n",
        "print(f\"Before pruning: Non-zero weights = {non_zero_weights_before}, Total weights = {total_weights_before}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AUFCP9AsBqb1",
        "outputId": "4d5321b8-51db-49d4-9199-2c2da1a8dda0"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Before pruning: Non-zero weights = 121543379, Total weights = 121543392\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1단계: 매그니튜드 기반 프루닝\n",
        "def magnitude_based_pruning(layer, sparsity):\n",
        "    \"\"\"매그니튜드 기반 프루닝\"\"\"\n",
        "    if hasattr(layer, 'kernel'):\n",
        "        weights, biases = layer.get_weights()\n",
        "        threshold = np.percentile(np.abs(weights), sparsity * 100)\n",
        "        pruned_weights = np.where(np.abs(weights) < threshold, 0, weights)\n",
        "        layer.set_weights([pruned_weights, biases])\n",
        "\n",
        "# 2단계: 가우시안 기반 프루닝\n",
        "def gaussian_importance(weights):\n",
        "    \"\"\"가중치의 중요도를 가우시안 분포로 계산\"\"\"\n",
        "    mean = np.mean(weights)\n",
        "    std = np.std(weights)\n",
        "    importance = norm.pdf(weights, loc=mean, scale=std)\n",
        "    return importance\n",
        "\n",
        "def gaussian_pruning(layer, threshold_ratio=0.1):\n",
        "    \"\"\"가우시안 기반 프루닝\"\"\"\n",
        "    if hasattr(layer, 'kernel'):\n",
        "        weights, biases = layer.get_weights()\n",
        "        importance = gaussian_importance(weights)\n",
        "        threshold = np.percentile(importance, threshold_ratio * 100)\n",
        "        pruned_weights = np.where(importance < threshold, 0, weights)\n",
        "        layer.set_weights([pruned_weights, biases])\n",
        "\n",
        "# 프루닝 수행: 먼저 매그니튜드 기반 프루닝, 그 다음 가우시안 기반 프루닝\n",
        "def combined_pruning(model, magnitude_sparsity=0.5, gaussian_threshold_ratio=0.1):\n",
        "    for layer in model.layers:\n",
        "        if hasattr(layer, 'kernel'):\n",
        "            # 1단계: 매그니튜드 기반 프루닝\n",
        "            magnitude_based_pruning(layer, magnitude_sparsity)\n",
        "            # 2단계: 가우시안 기반 프루닝\n",
        "            gaussian_pruning(layer, gaussian_threshold_ratio)\n",
        "\n",
        "# 모델의 각 레이어에 대해 프루닝 수행\n",
        "combined_pruning(model, magnitude_sparsity=0.5, gaussian_threshold_ratio=0.1)"
      ],
      "metadata": {
        "id": "_joc6z7F5SnT"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 프루닝 후 가중치 비율 계산\n",
        "non_zero_weights_after, total_weights_after = calculate_non_zero_weights(model)\n",
        "print(f\"After pruning: Non-zero weights = {non_zero_weights_after}, Total weights = {total_weights_after}\")\n",
        "\n",
        "# 최종 가중치 비율 계산\n",
        "final_weight_ratio = non_zero_weights_after / total_weights_after\n",
        "print(f\"Final non-zero weight ratio: {final_weight_ratio:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zPDnwvjr7QR7",
        "outputId": "1cebac4e-97ae-4613-939c-29b0d83b3c4f"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "After pruning: Non-zero weights = 48617360, Total weights = 121543392\n",
            "Final non-zero weight ratio: 0.4000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 이후 모델 재학습 및 평가 수행\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "history = model.fit(X_train, y_train_categorical, epochs=10, validation_data=(X_val, y_val_categorical))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yNCnoxXz5Spx",
        "outputId": "f606021a-9682-429f-f5cc-ffed61a6caef"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "394/394 [==============================] - 204s 515ms/step - loss: 0.8491 - accuracy: 0.6282 - val_loss: 0.4366 - val_accuracy: 0.9215\n",
            "Epoch 2/5\n",
            "394/394 [==============================] - 200s 507ms/step - loss: 0.2196 - accuracy: 0.9124 - val_loss: 0.0572 - val_accuracy: 0.9985\n",
            "Epoch 3/5\n",
            "394/394 [==============================] - 201s 511ms/step - loss: 0.0299 - accuracy: 0.9917 - val_loss: 0.2901 - val_accuracy: 0.8637\n",
            "Epoch 4/5\n",
            "394/394 [==============================] - 203s 515ms/step - loss: 0.0045 - accuracy: 0.9989 - val_loss: 8.2674e-04 - val_accuracy: 1.0000\n",
            "Epoch 5/5\n",
            "394/394 [==============================] - 204s 519ms/step - loss: 0.1230 - accuracy: 0.9588 - val_loss: 0.0604 - val_accuracy: 0.9963\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 최종 평가\n",
        "test_loss, test_accuracy = model.evaluate(X_test, y_test_categorical)\n",
        "print(f'Test accuracy after combined pruning: {test_accuracy}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tngjqMC15SsR",
        "outputId": "f9b18eca-4d3d-452a-8070-d4bcffb8f575"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "85/85 [==============================] - 4s 44ms/step - loss: 0.0654 - accuracy: 0.9967\n",
            "Test accuracy after combined pruning: 0.996666669845581\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 스트립 프루닝 적용\n",
        "model_stripped = tfmot.sparsity.keras.strip_pruning(model)\n",
        "\n",
        "# 스트립 프루닝 후 모델 저장\n",
        "model_stripped.save('pruned_model_stripped.h5')\n",
        "\n",
        "# 스트립 프루닝 후 모델 사이즈 측정\n",
        "pruned_model_size = os.path.getsize('pruned_model_stripped.h5') / (1024 * 1024)\n",
        "print(f\"Stripped Pruned Model Size: {pruned_model_size:.2f} MB\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bgELaxEQ5TGS",
        "outputId": "4fc26bd6-d3e2-4096-b861-b93f2fe279f6"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stripped Pruned Model Size: 463.71 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IX5bD1Ay5TIx"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pWzKNkUL5TK5"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "L5QVFNY25TNp"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1oFzuQHE5TP6"
      },
      "execution_count": 15,
      "outputs": []
    }
  ]
}